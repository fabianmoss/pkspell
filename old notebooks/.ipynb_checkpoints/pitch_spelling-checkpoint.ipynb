{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fosfrancesco/pitch-spelling/blob/main/rnncrf_pitch_spelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fifMg_hxNSOg",
    "outputId": "a8b320f9-4231-40d9-8f10-a7b8acd1da37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-crf\n",
      "  Downloading https://files.pythonhosted.org/packages/96/7d/4c4688e26ea015fc118a0327e5726e6596836abce9182d3738be8ec2e32a/pytorch_crf-0.7.2-py3-none-any.whl\n",
      "Installing collected packages: pytorch-crf\n",
      "Successfully installed pytorch-crf-0.7.2\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pytorch-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "hsciybUBNkur"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "import music21 as m21\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "import sklearn\n",
    "import music21 as m21\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchcrf import CRF\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook, notebook\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import time\n",
    "\n",
    "import kmeans1d\n",
    "import jenkspy\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "# import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Naq6UG5jRbyK"
   },
   "source": [
    "# RNN-CRF for Pitch Spelling\n",
    "\n",
    "Dataset: different authors from ASAP collection\n",
    "Challenges:\n",
    "- extremely long sequences\n",
    "- small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2mHJvrZ2Wo_e",
    "outputId": "1319f78b-cfb1-4e2a-937c-c47cf952757c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'C'), (1, 'B#'), (2, 'D--'), (3, 'C#'), (4, 'B##'), (5, 'D-'), (6, 'D'), (7, 'C##'), (8, 'E--'), (9, 'D#'), (10, 'E-'), (11, 'F--'), (12, 'E'), (13, 'D##'), (14, 'F-'), (15, 'F'), (16, 'E#'), (17, 'G--'), (18, 'F#'), (19, 'E##'), (20, 'G-'), (21, 'G'), (22, 'F##'), (23, 'A--'), (24, 'G#'), (25, 'A-'), (26, 'A'), (27, 'G##'), (28, 'B--'), (29, 'A#'), (30, 'B-'), (31, 'C--'), (32, 'B'), (33, 'A##'), (34, 'C-')]\n",
      "['D--', 'B##', 'C##', 'E--', 'F--', 'D##', 'G--', 'E##', 'F##', 'A--', 'G##', 'B--', 'C--', 'A##']\n",
      "[(0, 'P1'), (1, 'd2'), (2, 'A7'), (3, 'm2'), (4, 'A1'), (5, 'M2'), (6, 'd3'), (7, 'AA1'), (8, 'm3'), (9, 'A2'), (10, 'M3'), (11, 'd4'), (12, 'AA2'), (13, 'P4'), (14, 'A3'), (15, 'd5'), (16, 'A4'), (17, 'P5'), (18, 'd6'), (19, 'AA4'), (20, 'm6'), (21, 'A5'), (22, 'M6'), (23, 'd7'), (24, 'AA5'), (25, 'm7'), (26, 'A6'), (27, 'M7'), (28, 'd1'), (29, 'AA6')]\n"
     ]
    }
   ],
   "source": [
    "pitches_dict = {\n",
    "    0 : [\"C\",\"B#\",\"D--\"], # nn.Linear(input_size+context_size, 3)\n",
    "    1 : [\"C#\",\"B##\",\"D-\"], # nn.Linear(input_size+context_size, 2)\n",
    "    2 : [\"D\",\"C##\",\"E--\"], # nn.Linear(input_size+context_size, 3)\n",
    "    3 : [\"D#\",\"E-\",\"F--\"],\n",
    "    4 : [\"E\",\"D##\",\"F-\"],\n",
    "    5 : [\"F\",\"E#\",\"G--\"],\n",
    "    6 : [\"F#\",\"E##\",\"G-\"],\n",
    "    7 : [\"G\",\"F##\",\"A--\"],\n",
    "    8 : [\"G#\",\"A-\"],\n",
    "    9 : [\"A\",\"G##\",\"B--\"],\n",
    "    10 : [\"A#\",\"B-\",\"C--\"],\n",
    "    11 : [\"B\",\"A##\",\"C-\"]\n",
    "}\n",
    "\n",
    "accepted_pitches = [ii for i in pitches_dict.values() for ii in i]\n",
    "print([e for e in enumerate(accepted_pitches)])\n",
    "\n",
    "double_acc_pitches = [ii for i in pitches_dict.values() for ii in i if ii.endswith(\"##\") or  ii.endswith(\"--\") ]\n",
    "print(double_acc_pitches)\n",
    "\n",
    "def score2midi_numbers(score):\n",
    "    return [p.midi%12 for n in score.flat.notes for p in n.pitches]\n",
    "\n",
    "def score2pitches(score):\n",
    "    return [p.name for n in score.flat.notes for p in n.pitches]\n",
    "\n",
    "interval_dict = {\n",
    "    0 : [\"P1\",\"d2\",\"A7\"], \n",
    "    1 : [\"m2\",\"A1\"], \n",
    "    2 : [\"M2\",\"d3\",\"AA1\"], \n",
    "    3 : [\"m3\",\"A2\"],\n",
    "    4 : [\"M3\",\"d4\",\"AA2\"],\n",
    "    5 : [\"P4\",\"A3\"],\n",
    "    6 : [\"d5\",\"A4\"],\n",
    "    7 : [\"P5\",\"d6\",\"AA4\"],\n",
    "    8 : [\"m6\",\"A5\"],\n",
    "    9 : [\"M6\",\"d7\",\"AA5\"],\n",
    "    10 : [\"m7\",\"A6\"],\n",
    "    11 : [\"M7\",\"d1\",\"AA6\"]\n",
    "}\n",
    "\n",
    "accepted_intervals = [ii for i in interval_dict.values() for ii in i]\n",
    "print([e for e in enumerate(accepted_intervals)])\n",
    "\n",
    "def transp_score(score):\n",
    "    \"\"\" For each input return len(accepted_intervals) transposed scores\"\"\"\n",
    "    return [score.transpose(interval) for interval in accepted_intervals]\n",
    "\n",
    "def smart_transp_score(score):\n",
    "    \"\"\" For each chromatic interval chose the interval that lead to the smallest number of accidentals\"\"\"\n",
    "    scores = []\n",
    "    for chromatic_int in interval_dict.keys():\n",
    "        temp_scores = []\n",
    "        temp_acc_number = []\n",
    "        for diat_interval in interval_dict[chromatic_int]:\n",
    "            new_score = score.transpose(diat_interval)\n",
    "            temp_scores.append(new_score)\n",
    "            temp_acc_number.append(sum([pitch.count(\"#\") + pitch.count(\"-\") for pitch in score2pitches(new_score)]))\n",
    "            # print(\"choice:\", [note.name for note in temp_scores[-1].flat.notes][0:10],\"acc:\",temp_acc_number[-1] )\n",
    "        #keep only the one with the lowest number of accidentals\n",
    "        min_index = np.argmin(temp_acc_number)\n",
    "        # print(\"preferred the number\", min_index)\n",
    "        scores.append(temp_scores[min_index])\n",
    "    return scores\n",
    "\n",
    "def acc_simple_enough(score,accepted_ratio = 0.2 ):\n",
    "    pitches = score2pitches(score)\n",
    "    double_acc = sum(el in double_acc_pitches for el in pitches)\n",
    "    if double_acc/len(pitches) < accepted_ratio:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "diatonic_pitches = [\"C\",\"D\", \"E\", \"F\", \"G\", \"A\", \"B\"]\n",
    "\n",
    "# #test acc_simple_enough()\n",
    "# score = m21.converter.parse(paths[356])\n",
    "# scores = smart_transp_score(score)\n",
    "# #delete the pieces with non accepted pitches (e.g. triple sharps)\n",
    "# scores = [s for s in scores if all(pitch in accepted_pitches for pitch in score2pitches(s))]\n",
    "# for s in scores:\n",
    "#     print(s.parts[0].flat.getElementsByClass(m21.key.KeySignature)[0], \"simple enough:\", acc_simple_enough(s))\n",
    "#     print([n.name for n in s.flat.notes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gw-SuL4ZB_2C"
   },
   "source": [
    "## Import ASAP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrZ0BwLEj2Gp",
    "outputId": "6b521f78-28db-4d4f-f4ef-9345c5d91db9"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/fosfrancesco/pitch-spelling.git\n",
    "\n",
    "basepath = \"./\" #to change if running locally or on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WaINjDS2kpxE"
   },
   "outputs": [],
   "source": [
    "# load the asap datasets\n",
    "with open(Path(basepath,'datasets','baroque_aug_asap.pkl'), 'rb') as fid:\n",
    "     dataset_baroque = pickle.load( fid)\n",
    "\n",
    "with open(Path(basepath,'datasets','classical_aug_asap.pkl'), 'rb') as fid:\n",
    "     dataset_classical = pickle.load( fid)\n",
    "\n",
    "with open(Path(basepath,'datasets','romantic_aug_asap.pkl'), 'rb') as fid:\n",
    "     dataset_romantic = pickle.load( fid)\n",
    "        \n",
    "# with open(Path(basepath,'datasets','remaining_aug_asap.pkl'), 'rb') as fid:\n",
    "#      dataset_remaining = pickle.load( fid)\n",
    "\n",
    "# merge the three files together\n",
    "# full_dict_dataset = dataset_baroque + dataset_classical + dataset_romantic + dataset_remaining\n",
    "full_dict_dataset = dataset_baroque + dataset_classical + dataset_romantic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYQdkJAiTS6_",
    "outputId": "72835948-2884-40bb-e5b4-6ebbc8488895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191 different pieces\n",
      "Average number of notes:  2219.6285387474977\n"
     ]
    }
   ],
   "source": [
    "paths = list(set([e[\"original_path\"] for e in full_dict_dataset ]))\n",
    "\n",
    "# print(paths)\n",
    "print(len(paths), \"different pieces\")\n",
    "print(\"Average number of notes: \", np.mean([len(e[\"midi_number\"]) for e in full_dict_dataset ]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMdKkzNnCTrK"
   },
   "source": [
    "## Chose the convenient data augmentation\n",
    "Two possibilities:\n",
    "- for each chromatic interval, take only the diatonic transposition that produce the smallest number of accidentals (or the original if present)\n",
    "- take only a certain interval of time signatures\n",
    "\n",
    "The second is probably better for a smaller and simple dataset, but gives the problem of chosing between for example F# and G# that are both present in this bigger dataset. So we go for the first criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oign7EZ9BSX4",
    "outputId": "9aa3f694-289a-43fd-fd14-9cad3b8dd3b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No options for Chopin/Etudes_op_25/10/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Etudes_op_25/10/xml_score.musicxml . Chromatic:  9\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  9\n",
      "No options for Chopin/Sonata_2/2nd/xml_score.musicxml . Chromatic:  11\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  1\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  3\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  8\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  10\n",
      "No options for Chopin/Sonata_3/4th/xml_score.musicxml . Chromatic:  11\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  1\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  4\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  6\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  9\n",
      "No options for Schubert/Wanderer_fantasie/xml_score.musicxml . Chromatic:  11\n",
      "No options for Chopin/Ballades/4/xml_score.musicxml . Chromatic:  6\n",
      "No options for Chopin/Etudes_op_10/4/xml_score.musicxml . Chromatic:  4\n",
      "No options for Chopin/Etudes_op_10/4/xml_score.musicxml . Chromatic:  9\n",
      "No options for Chopin/Sonata_2/1st_no_repeat/xml_score.musicxml . Chromatic:  1\n",
      "Beethoven/Piano_Sonatas/23-1/xml_score.musicxml P1 -4\n",
      "['E', 'D', 'F', 'E-', 'E', 'D', 'G', 'F', 'E', 'D']\n",
      "[4, 2, 5, 3, 4, 2, 7, 5, 4, 2]\n",
      "Beethoven/Piano_Sonatas/23-1/xml_score.musicxml A1 3\n",
      "['E#', 'D#', 'F#', 'E', 'E#', 'D#', 'G#', 'F#', 'E#', 'D#']\n",
      "[5, 3, 6, 4, 5, 3, 8, 6, 5, 3]\n",
      "Beethoven/Piano_Sonatas/23-1/xml_score.musicxml M2 -2\n",
      "['F#', 'E', 'G', 'F', 'F#', 'E', 'A', 'G', 'F#', 'E']\n",
      "[6, 4, 7, 5, 6, 4, 9, 7, 6, 4]\n",
      "Beethoven/Piano_Sonatas/23-1/xml_score.musicxml m3 -7\n",
      "['G', 'F', 'A-', 'G-', 'G', 'F', 'B-', 'A-', 'G', 'F']\n",
      "[7, 5, 8, 6, 7, 5, 10, 8, 7, 5]\n",
      "Beethoven/Piano_Sonatas/23-1/xml_score.musicxml M3 0\n",
      "['G#', 'F#', 'A', 'G', 'G#', 'F#', 'B', 'A', 'G#', 'F#']\n",
      "[8, 6, 9, 7, 8, 6, 11, 9, 8, 6]\n",
      "Beethoven/Piano_Sonatas/23-1/xml_score.musicxml P4 -5\n",
      "['A', 'G', 'B-', 'A-', 'A', 'G', 'C', 'B-', 'A', 'G']\n",
      "[9, 7, 10, 8, 9, 7, 0, 10, 9, 7]\n",
      "Beethoven/Piano_Sonatas/23-1/xml_score.musicxml A4 2\n",
      "['A#', 'G#', 'B', 'A', 'A#', 'G#', 'C#', 'B', 'A#', 'G#']\n",
      "[10, 8, 11, 9, 10, 8, 1, 11, 10, 8]\n",
      "Beethoven/Piano_Sonatas/23-1/xml_score.musicxml P5 -3\n",
      "['B', 'A', 'C', 'B-', 'B', 'A', 'D', 'C', 'B', 'A']\n",
      "[11, 9, 0, 10, 11, 9, 2, 0, 11, 9]\n",
      "Beethoven/Piano_Sonatas/23-1/xml_score.musicxml A5 4\n",
      "['B#', 'A#', 'C#', 'B', 'B#', 'A#', 'D#', 'C#', 'B#', 'A#']\n",
      "[0, 10, 1, 11, 0, 10, 3, 1, 0, 10]\n",
      "Beethoven/Piano_Sonatas/23-1/xml_score.musicxml M6 -1\n",
      "['C#', 'B', 'D', 'C', 'C#', 'B', 'E', 'D', 'C#', 'B']\n",
      "[1, 11, 2, 0, 1, 11, 4, 2, 1, 11]\n",
      "Beethoven/Piano_Sonatas/23-1/xml_score.musicxml m7 -6\n",
      "['D', 'C', 'E-', 'D-', 'D', 'C', 'F', 'E-', 'D', 'C']\n",
      "[2, 0, 3, 1, 2, 0, 5, 3, 2, 0]\n",
      "Beethoven/Piano_Sonatas/23-1/xml_score.musicxml M7 1\n",
      "['D#', 'C#', 'E', 'D', 'D#', 'C#', 'F#', 'E', 'D#', 'C#']\n",
      "[3, 1, 4, 2, 3, 1, 6, 4, 3, 1]\n",
      "Beethoven/Piano_Sonatas/9-1/xml_score.musicxml P1 4\n",
      "['B', 'E', 'G#', 'B', 'E', 'G#', 'B', 'E', 'G#', 'B']\n",
      "[11, 4, 8, 11, 4, 8, 11, 4, 8, 11]\n",
      "Beethoven/Piano_Sonatas/9-1/xml_score.musicxml m2 -1\n",
      "['C', 'F', 'A', 'C', 'F', 'A', 'C', 'F', 'A', 'C']\n",
      "[0, 5, 9, 0, 5, 9, 0, 5, 9, 0]\n",
      "Beethoven/Piano_Sonatas/9-1/xml_score.musicxml M2 6\n",
      "['C#', 'F#', 'A#', 'C#', 'F#', 'A#', 'C#', 'F#', 'A#', 'C#']\n",
      "[1, 6, 10, 1, 6, 10, 1, 6, 10, 1]\n",
      "Beethoven/Piano_Sonatas/9-1/xml_score.musicxml m3 1\n",
      "['D', 'G', 'B', 'D', 'G', 'B', 'D', 'G', 'B', 'D']\n",
      "[2, 7, 11, 2, 7, 11, 2, 7, 11, 2]\n",
      "Beethoven/Piano_Sonatas/9-1/xml_score.musicxml d4 -4\n",
      "['E-', 'A-', 'C', 'E-', 'A-', 'C', 'E-', 'A-', 'C', 'E-']\n",
      "[3, 8, 0, 3, 8, 0, 3, 8, 0, 3]\n",
      "Beethoven/Piano_Sonatas/9-1/xml_score.musicxml P4 3\n",
      "['E', 'A', 'C#', 'E', 'A', 'C#', 'E', 'A', 'C#', 'E']\n",
      "[4, 9, 1, 4, 9, 1, 4, 9, 1, 4]\n",
      "Beethoven/Piano_Sonatas/9-1/xml_score.musicxml d5 -2\n",
      "['F', 'B-', 'D', 'F', 'B-', 'D', 'F', 'B-', 'D', 'F']\n",
      "[5, 10, 2, 5, 10, 2, 5, 10, 2, 5]\n",
      "Beethoven/Piano_Sonatas/9-1/xml_score.musicxml P5 5\n",
      "['F#', 'B', 'D#', 'F#', 'B', 'D#', 'F#', 'B', 'D#', 'F#']\n",
      "[6, 11, 3, 6, 11, 3, 6, 11, 3, 6]\n",
      "Beethoven/Piano_Sonatas/9-1/xml_score.musicxml m6 0\n",
      "['G', 'C', 'E', 'G', 'C', 'E', 'G', 'C', 'E', 'G']\n",
      "[7, 0, 4, 7, 0, 4, 7, 0, 4, 7]\n",
      "Beethoven/Piano_Sonatas/9-1/xml_score.musicxml d7 -5\n",
      "['A-', 'D-', 'F', 'A-', 'D-', 'F', 'A-', 'D-', 'F', 'A-']\n",
      "[8, 1, 5, 8, 1, 5, 8, 1, 5, 8]\n",
      "Beethoven/Piano_Sonatas/9-1/xml_score.musicxml m7 2\n",
      "['A', 'D', 'F#', 'A', 'D', 'F#', 'A', 'D', 'F#', 'A']\n",
      "[9, 2, 6, 9, 2, 6, 9, 2, 6, 9]\n",
      "Beethoven/Piano_Sonatas/9-1/xml_score.musicxml d1 -3\n",
      "['B-', 'E-', 'G', 'B-', 'E-', 'G', 'B-', 'E-', 'G', 'B-']\n",
      "[10, 3, 7, 10, 3, 7, 10, 3, 7, 10]\n",
      "Bach/Fugue/bwv_889/xml_score.musicxml P1 0\n",
      "['E', 'C', 'F', 'G#', 'D', 'B', 'E', 'C', 'A', 'A']\n",
      "[4, 0, 5, 8, 2, 11, 4, 0, 9, 9]\n",
      "Bach/Fugue/bwv_889/xml_score.musicxml m2 -5\n",
      "['F', 'D-', 'G-', 'A', 'E-', 'C', 'F', 'D-', 'B-', 'B-']\n",
      "[5, 1, 6, 9, 3, 0, 5, 1, 10, 10]\n",
      "Bach/Fugue/bwv_889/xml_score.musicxml M2 2\n",
      "['F#', 'D', 'G', 'A#', 'E', 'C#', 'F#', 'D', 'B', 'B']\n",
      "[6, 2, 7, 10, 4, 1, 6, 2, 11, 11]\n",
      "Bach/Fugue/bwv_889/xml_score.musicxml m3 -3\n",
      "['G', 'E-', 'A-', 'B', 'F', 'D', 'G', 'E-', 'C', 'C']\n",
      "[7, 3, 8, 11, 5, 2, 7, 3, 0, 0]\n",
      "Bach/Fugue/bwv_889/xml_score.musicxml M3 4\n",
      "['G#', 'E', 'A', 'B#', 'F#', 'D#', 'G#', 'E', 'C#', 'C#']\n",
      "[8, 4, 9, 0, 6, 3, 8, 4, 1, 1]\n",
      "Bach/Fugue/bwv_889/xml_score.musicxml P4 -1\n",
      "['A', 'F', 'B-', 'C#', 'G', 'E', 'A', 'F', 'D', 'D']\n",
      "[9, 5, 10, 1, 7, 4, 9, 5, 2, 2]\n",
      "Bach/Fugue/bwv_889/xml_score.musicxml d5 -6\n",
      "['B-', 'G-', 'C-', 'D', 'A-', 'F', 'B-', 'G-', 'E-', 'E-']\n",
      "[10, 6, 11, 2, 8, 5, 10, 6, 3, 3]\n",
      "Bach/Fugue/bwv_889/xml_score.musicxml P5 1\n",
      "['B', 'G', 'C', 'D#', 'A', 'F#', 'B', 'G', 'E', 'E']\n",
      "[11, 7, 0, 3, 9, 6, 11, 7, 4, 4]\n",
      "Bach/Fugue/bwv_889/xml_score.musicxml m6 -4\n",
      "['C', 'A-', 'D-', 'E', 'B-', 'G', 'C', 'A-', 'F', 'F']\n",
      "[0, 8, 1, 4, 10, 7, 0, 8, 5, 5]\n",
      "Bach/Fugue/bwv_889/xml_score.musicxml M6 3\n",
      "['C#', 'A', 'D', 'E#', 'B', 'G#', 'C#', 'A', 'F#', 'F#']\n",
      "[1, 9, 2, 5, 11, 8, 1, 9, 6, 6]\n",
      "Bach/Fugue/bwv_889/xml_score.musicxml m7 -2\n",
      "['D', 'B-', 'E-', 'F#', 'C', 'A', 'D', 'B-', 'G', 'G']\n",
      "[2, 10, 3, 6, 0, 9, 2, 10, 7, 7]\n",
      "Bach/Fugue/bwv_889/xml_score.musicxml d1 -7\n",
      "['E-', 'C-', 'F-', 'G', 'D-', 'B-', 'E-', 'C-', 'A-', 'A-']\n",
      "[3, 11, 4, 7, 1, 10, 3, 11, 8, 8]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml P1 3\n",
      "['A', 'A', 'A', 'E', 'E', 'E', 'E', 'E', 'D', 'D']\n",
      "[9, 9, 9, 4, 4, 4, 4, 4, 2, 2]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml m2 -2\n",
      "['B-', 'B-', 'B-', 'F', 'F', 'F', 'F', 'F', 'E-', 'E-']\n",
      "[10, 10, 10, 5, 5, 5, 5, 5, 3, 3]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml M2 5\n",
      "['B', 'B', 'B', 'F#', 'F#', 'F#', 'F#', 'F#', 'E', 'E']\n",
      "[11, 11, 11, 6, 6, 6, 6, 6, 4, 4]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml m3 0\n",
      "['C', 'C', 'C', 'G', 'G', 'G', 'G', 'G', 'F', 'F']\n",
      "[0, 0, 0, 7, 7, 7, 7, 7, 5, 5]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml M3 7\n",
      "['C#', 'C#', 'C#', 'G#', 'G#', 'G#', 'G#', 'G#', 'F#', 'F#']\n",
      "[1, 1, 1, 8, 8, 8, 8, 8, 6, 6]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml P4 2\n",
      "['D', 'D', 'D', 'A', 'A', 'A', 'A', 'A', 'G', 'G']\n",
      "[2, 2, 2, 9, 9, 9, 9, 9, 7, 7]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml d5 -3\n",
      "['E-', 'E-', 'E-', 'B-', 'B-', 'B-', 'B-', 'B-', 'A-', 'A-']\n",
      "[3, 3, 3, 10, 10, 10, 10, 10, 8, 8]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml P5 4\n",
      "['E', 'E', 'E', 'B', 'B', 'B', 'B', 'B', 'A', 'A']\n",
      "[4, 4, 4, 11, 11, 11, 11, 11, 9, 9]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml m6 -1\n",
      "['F', 'F', 'F', 'C', 'C', 'C', 'C', 'C', 'B-', 'B-']\n",
      "[5, 5, 5, 0, 0, 0, 0, 0, 10, 10]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml M6 6\n",
      "['F#', 'F#', 'F#', 'C#', 'C#', 'C#', 'C#', 'C#', 'B', 'B']\n",
      "[6, 6, 6, 1, 1, 1, 1, 1, 11, 11]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml m7 1\n",
      "['G', 'G', 'G', 'D', 'D', 'D', 'D', 'D', 'C', 'C']\n",
      "[7, 7, 7, 2, 2, 2, 2, 2, 0, 0]\n",
      "Beethoven/Piano_Sonatas/2-1/xml_score.musicxml d1 -4\n",
      "['A-', 'A-', 'A-', 'E-', 'E-', 'E-', 'E-', 'E-', 'D-', 'D-']\n",
      "[8, 8, 8, 3, 3, 3, 3, 3, 1, 1]\n",
      "Beethoven/Piano_Sonatas/5-1/xml_score.musicxml P1 -3\n",
      "['E-', 'G', 'C', 'C', 'E-', 'G', 'C', 'G', 'E-', 'C']\n",
      "[3, 7, 0, 0, 3, 7, 0, 7, 3, 0]\n",
      "Beethoven/Piano_Sonatas/5-1/xml_score.musicxml A1 4\n",
      "['E', 'G#', 'C#', 'C#', 'E', 'G#', 'C#', 'G#', 'E', 'C#']\n",
      "[4, 8, 1, 1, 4, 8, 1, 8, 4, 1]\n",
      "Beethoven/Piano_Sonatas/5-1/xml_score.musicxml M2 -1\n",
      "['F', 'A', 'D', 'D', 'F', 'A', 'D', 'A', 'F', 'D']\n",
      "[5, 9, 2, 2, 5, 9, 2, 9, 5, 2]\n",
      "Beethoven/Piano_Sonatas/5-1/xml_score.musicxml m3 -6\n",
      "['G-', 'B-', 'E-', 'E-', 'G-', 'B-', 'E-', 'B-', 'G-', 'E-']\n",
      "[6, 10, 3, 3, 6, 10, 3, 10, 6, 3]\n",
      "Beethoven/Piano_Sonatas/5-1/xml_score.musicxml M3 1\n",
      "['G', 'B', 'E', 'E', 'G', 'B', 'E', 'B', 'G', 'E']\n",
      "[7, 11, 4, 4, 7, 11, 4, 11, 7, 4]\n",
      "Beethoven/Piano_Sonatas/5-1/xml_score.musicxml P4 -4\n",
      "['A-', 'C', 'F', 'F', 'A-', 'C', 'F', 'C', 'A-', 'F']\n",
      "[8, 0, 5, 5, 8, 0, 5, 0, 8, 5]\n",
      "Beethoven/Piano_Sonatas/5-1/xml_score.musicxml A4 3\n",
      "['A', 'C#', 'F#', 'F#', 'A', 'C#', 'F#', 'C#', 'A', 'F#']\n",
      "[9, 1, 6, 6, 9, 1, 6, 1, 9, 6]\n",
      "Beethoven/Piano_Sonatas/5-1/xml_score.musicxml P5 -2\n",
      "['B-', 'D', 'G', 'G', 'B-', 'D', 'G', 'D', 'B-', 'G']\n",
      "[10, 2, 7, 7, 10, 2, 7, 2, 10, 7]\n",
      "Beethoven/Piano_Sonatas/5-1/xml_score.musicxml A5 5\n",
      "['B', 'D#', 'G#', 'G#', 'B', 'D#', 'G#', 'D#', 'B', 'G#']\n",
      "[11, 3, 8, 8, 11, 3, 8, 3, 11, 8]\n",
      "Beethoven/Piano_Sonatas/5-1/xml_score.musicxml M6 0\n",
      "['C', 'E', 'A', 'A', 'C', 'E', 'A', 'E', 'C', 'A']\n",
      "[0, 4, 9, 9, 0, 4, 9, 4, 0, 9]\n",
      "Beethoven/Piano_Sonatas/5-1/xml_score.musicxml m7 -5\n",
      "['D-', 'F', 'B-', 'B-', 'D-', 'F', 'B-', 'F', 'D-', 'B-']\n",
      "[1, 5, 10, 10, 1, 5, 10, 5, 1, 10]\n",
      "Beethoven/Piano_Sonatas/5-1/xml_score.musicxml M7 2\n",
      "['D', 'F#', 'B', 'B', 'D', 'F#', 'B', 'F#', 'D', 'B']\n",
      "[2, 6, 11, 11, 2, 6, 11, 6, 2, 11]\n",
      "Bach/Italian_concerto/xml_score.musicxml P1 -1\n",
      "['F', 'D', 'D', 'D', 'F', 'D', 'G', 'E', 'A', 'F']\n",
      "[5, 2, 2, 2, 5, 2, 7, 4, 9, 5]\n",
      "Bach/Italian_concerto/xml_score.musicxml m2 -6\n",
      "['G-', 'E-', 'E-', 'E-', 'G-', 'E-', 'A-', 'F', 'B-', 'G-']\n",
      "[6, 3, 3, 3, 6, 3, 8, 5, 10, 6]\n",
      "Bach/Italian_concerto/xml_score.musicxml M2 1\n",
      "['G', 'E', 'E', 'E', 'G', 'E', 'A', 'F#', 'B', 'G']\n",
      "[7, 4, 4, 4, 7, 4, 9, 6, 11, 7]\n",
      "Bach/Italian_concerto/xml_score.musicxml m3 -4\n",
      "['A-', 'F', 'F', 'F', 'A-', 'F', 'B-', 'G', 'C', 'A-']\n",
      "[8, 5, 5, 5, 8, 5, 10, 7, 0, 8]\n",
      "Bach/Italian_concerto/xml_score.musicxml M3 3\n",
      "['A', 'F#', 'F#', 'F#', 'A', 'F#', 'B', 'G#', 'C#', 'A']\n",
      "[9, 6, 6, 6, 9, 6, 11, 8, 1, 9]\n",
      "Bach/Italian_concerto/xml_score.musicxml P4 -2\n",
      "['B-', 'G', 'G', 'G', 'B-', 'G', 'C', 'A', 'D', 'B-']\n",
      "[10, 7, 7, 7, 10, 7, 0, 9, 2, 10]\n",
      "Bach/Italian_concerto/xml_score.musicxml A4 5\n",
      "['B', 'G#', 'G#', 'G#', 'B', 'G#', 'C#', 'A#', 'D#', 'B']\n",
      "[11, 8, 8, 8, 11, 8, 1, 10, 3, 11]\n",
      "Bach/Italian_concerto/xml_score.musicxml P5 0\n",
      "['C', 'A', 'A', 'A', 'C', 'A', 'D', 'B', 'E', 'C']\n",
      "[0, 9, 9, 9, 0, 9, 2, 11, 4, 0]\n",
      "Bach/Italian_concerto/xml_score.musicxml m6 -5\n",
      "['D-', 'B-', 'B-', 'B-', 'D-', 'B-', 'E-', 'C', 'F', 'D-']\n",
      "[1, 10, 10, 10, 1, 10, 3, 0, 5, 1]\n",
      "Bach/Italian_concerto/xml_score.musicxml M6 2\n",
      "['D', 'B', 'B', 'B', 'D', 'B', 'E', 'C#', 'F#', 'D']\n",
      "[2, 11, 11, 11, 2, 11, 4, 1, 6, 2]\n",
      "Bach/Italian_concerto/xml_score.musicxml m7 -3\n",
      "['E-', 'C', 'C', 'C', 'E-', 'C', 'F', 'D', 'G', 'E-']\n",
      "[3, 0, 0, 0, 3, 0, 5, 2, 7, 3]\n",
      "Bach/Italian_concerto/xml_score.musicxml M7 4\n",
      "['E', 'C#', 'C#', 'C#', 'E', 'C#', 'F#', 'D#', 'G#', 'E']\n",
      "[4, 1, 1, 1, 4, 1, 6, 3, 8, 4]\n",
      "Beethoven/Piano_Sonatas/28-1/xml_score.musicxml P1 3\n",
      "['G#', 'E', 'E', 'E', 'B', 'A', 'F#', 'D#', 'B', 'G#']\n",
      "[8, 4, 4, 4, 11, 9, 6, 3, 11, 8]\n",
      "Beethoven/Piano_Sonatas/28-1/xml_score.musicxml m2 -2\n",
      "['A', 'F', 'F', 'F', 'C', 'B-', 'G', 'E', 'C', 'A']\n",
      "[9, 5, 5, 5, 0, 10, 7, 4, 0, 9]\n",
      "Beethoven/Piano_Sonatas/28-1/xml_score.musicxml M2 5\n",
      "['A#', 'F#', 'F#', 'F#', 'C#', 'B', 'G#', 'E#', 'C#', 'A#']\n",
      "[10, 6, 6, 6, 1, 11, 8, 5, 1, 10]\n",
      "Beethoven/Piano_Sonatas/28-1/xml_score.musicxml m3 0\n",
      "['B', 'G', 'G', 'G', 'D', 'C', 'A', 'F#', 'D', 'B']\n",
      "[11, 7, 7, 7, 2, 0, 9, 6, 2, 11]\n",
      "Beethoven/Piano_Sonatas/28-1/xml_score.musicxml d4 -5\n",
      "['C', 'A-', 'A-', 'A-', 'E-', 'D-', 'B-', 'G', 'E-', 'C']\n",
      "[0, 8, 8, 8, 3, 1, 10, 7, 3, 0]\n",
      "Beethoven/Piano_Sonatas/28-1/xml_score.musicxml P4 2\n",
      "['C#', 'A', 'A', 'A', 'E', 'D', 'B', 'G#', 'E', 'C#']\n",
      "[1, 9, 9, 9, 4, 2, 11, 8, 4, 1]\n",
      "Beethoven/Piano_Sonatas/28-1/xml_score.musicxml d5 -3\n",
      "['D', 'B-', 'B-', 'B-', 'F', 'E-', 'C', 'A', 'F', 'D']\n",
      "[2, 10, 10, 10, 5, 3, 0, 9, 5, 2]\n",
      "Beethoven/Piano_Sonatas/28-1/xml_score.musicxml P5 4\n",
      "['D#', 'B', 'B', 'B', 'F#', 'E', 'C#', 'A#', 'F#', 'D#']\n",
      "[3, 11, 11, 11, 6, 4, 1, 10, 6, 3]\n",
      "Beethoven/Piano_Sonatas/28-1/xml_score.musicxml m6 -1\n",
      "['E', 'C', 'C', 'C', 'G', 'F', 'D', 'B', 'G', 'E']\n",
      "[4, 0, 0, 0, 7, 5, 2, 11, 7, 4]\n",
      "Beethoven/Piano_Sonatas/28-1/xml_score.musicxml d7 -6\n",
      "['F', 'D-', 'D-', 'D-', 'A-', 'G-', 'E-', 'C', 'A-', 'F']\n",
      "[5, 1, 1, 1, 8, 6, 3, 0, 8, 5]\n",
      "Beethoven/Piano_Sonatas/28-1/xml_score.musicxml m7 1\n",
      "['F#', 'D', 'D', 'D', 'A', 'G', 'E', 'C#', 'A', 'F#']\n",
      "[6, 2, 2, 2, 9, 7, 4, 1, 9, 6]\n",
      "Beethoven/Piano_Sonatas/28-1/xml_score.musicxml d1 -4\n",
      "['G', 'E-', 'E-', 'E-', 'B-', 'A-', 'F', 'D', 'B-', 'G']\n",
      "[7, 3, 3, 3, 10, 8, 5, 2, 10, 7]\n",
      "Bach/Fugue/bwv_887/xml_score.musicxml P1 5\n",
      "['G#', 'A#', 'B', 'A#', 'D#', 'D#', 'G#', 'B', 'A#', 'B']\n",
      "[8, 10, 11, 10, 3, 3, 8, 11, 10, 11]\n",
      "Bach/Fugue/bwv_887/xml_score.musicxml m2 0\n",
      "['A', 'B', 'C', 'B', 'E', 'E', 'A', 'C', 'B', 'C']\n",
      "[9, 11, 0, 11, 4, 4, 9, 0, 11, 0]\n",
      "Bach/Fugue/bwv_887/xml_score.musicxml d3 -5\n",
      "['B-', 'C', 'D-', 'C', 'F', 'F', 'B-', 'D-', 'C', 'D-']\n",
      "[10, 0, 1, 0, 5, 5, 10, 1, 0, 1]\n",
      "Bach/Fugue/bwv_887/xml_score.musicxml m3 2\n",
      "['B', 'C#', 'D', 'C#', 'F#', 'F#', 'B', 'D', 'C#', 'D']\n",
      "[11, 1, 2, 1, 6, 6, 11, 2, 1, 2]\n",
      "Bach/Fugue/bwv_887/xml_score.musicxml d4 -3\n",
      "['C', 'D', 'E-', 'D', 'G', 'G', 'C', 'E-', 'D', 'E-']\n",
      "[0, 2, 3, 2, 7, 7, 0, 3, 2, 3]\n",
      "Bach/Fugue/bwv_887/xml_score.musicxml P4 4\n",
      "['C#', 'D#', 'E', 'D#', 'G#', 'G#', 'C#', 'E', 'D#', 'E']\n",
      "[1, 3, 4, 3, 8, 8, 1, 4, 3, 4]\n",
      "Bach/Fugue/bwv_887/xml_score.musicxml d5 -1\n",
      "['D', 'E', 'F', 'E', 'A', 'A', 'D', 'F', 'E', 'F']\n",
      "[2, 4, 5, 4, 9, 9, 2, 5, 4, 5]\n",
      "Bach/Fugue/bwv_887/xml_score.musicxml d6 -6\n",
      "['E-', 'F', 'G-', 'F', 'B-', 'B-', 'E-', 'G-', 'F', 'G-']\n",
      "[3, 5, 6, 5, 10, 10, 3, 6, 5, 6]\n",
      "Bach/Fugue/bwv_887/xml_score.musicxml m6 1\n",
      "['E', 'F#', 'G', 'F#', 'B', 'B', 'E', 'G', 'F#', 'G']\n",
      "[4, 6, 7, 6, 11, 11, 4, 7, 6, 7]\n",
      "Bach/Fugue/bwv_887/xml_score.musicxml d7 -4\n",
      "['F', 'G', 'A-', 'G', 'C', 'C', 'F', 'A-', 'G', 'A-']\n",
      "[5, 7, 8, 7, 0, 0, 5, 8, 7, 8]\n",
      "Bach/Fugue/bwv_887/xml_score.musicxml m7 3\n",
      "['F#', 'G#', 'A', 'G#', 'C#', 'C#', 'F#', 'A', 'G#', 'A']\n",
      "[6, 8, 9, 8, 1, 1, 6, 9, 8, 9]\n",
      "Bach/Fugue/bwv_887/xml_score.musicxml d1 -2\n",
      "['G', 'A', 'B-', 'A', 'D', 'D', 'G', 'B-', 'A', 'B-']\n",
      "[7, 9, 10, 9, 2, 2, 7, 10, 9, 10]\n",
      "Beethoven/Piano_Sonatas/4-1/xml_score.musicxml P1 -3\n",
      "['B-', 'E-', 'G', 'E-', 'E-', 'E-', 'E-', 'E-', 'E-', 'G']\n",
      "[10, 3, 7, 3, 3, 3, 3, 3, 3, 7]\n",
      "Beethoven/Piano_Sonatas/4-1/xml_score.musicxml A1 4\n",
      "['B', 'E', 'G#', 'E', 'E', 'E', 'E', 'E', 'E', 'G#']\n",
      "[11, 4, 8, 4, 4, 4, 4, 4, 4, 8]\n",
      "Beethoven/Piano_Sonatas/4-1/xml_score.musicxml M2 -1\n",
      "['C', 'F', 'A', 'F', 'F', 'F', 'F', 'F', 'F', 'A']\n",
      "[0, 5, 9, 5, 5, 5, 5, 5, 5, 9]\n",
      "Beethoven/Piano_Sonatas/4-1/xml_score.musicxml m3 -6\n",
      "['D-', 'G-', 'B-', 'G-', 'G-', 'G-', 'G-', 'G-', 'G-', 'B-']\n",
      "[1, 6, 10, 6, 6, 6, 6, 6, 6, 10]\n",
      "Beethoven/Piano_Sonatas/4-1/xml_score.musicxml M3 1\n",
      "['D', 'G', 'B', 'G', 'G', 'G', 'G', 'G', 'G', 'B']\n",
      "[2, 7, 11, 7, 7, 7, 7, 7, 7, 11]\n"
     ]
    }
   ],
   "source": [
    "# choose only one enharmonic version for each chromatic interval for each piece\n",
    "dict_dataset = []\n",
    "for path in paths:\n",
    "    for c in range(12):\n",
    "        pieces_to_consider = [opus for opus in full_dict_dataset \n",
    "                              if (opus[\"original_path\"] == path and opus[\"transposed_of\"] in interval_dict[c])  ]\n",
    "        # if the original is in pieces_to_consider, go with the original\n",
    "        originals = [opus for opus in pieces_to_consider if opus[\"transposed_of\"] == \"P1\"]\n",
    "        if len(originals) == 1:\n",
    "            dict_dataset.append(originals[0])\n",
    "        else: #we go with the accidental minization criteria\n",
    "            n_accidentals = [sum([pitch.count(\"#\") + pitch.count(\"-\") for pitch in opus[\"pitches\"]]) \n",
    "                            for opus in pieces_to_consider]\n",
    "            if len(pieces_to_consider)>0:\n",
    "                dict_dataset.append(pieces_to_consider[np.argmin(n_accidentals)])\n",
    "            else:\n",
    "                print(\"No options for\", path, \". Chromatic: \",c )\n",
    "\n",
    "# accepted_ks = range(-5,6)\n",
    "# dict_dataset = [e for e in full_dict_dataset if e[\"key_signature\"] in accepted_ks]\n",
    "\n",
    "#test if it worked\n",
    "for i,e in enumerate(dict_dataset):\n",
    "    print(e[\"original_path\"], e[\"transposed_of\"], e[\"key_signature\"])\n",
    "    print(e[\"pitches\"][:10])\n",
    "    print(e[\"midi_number\"][:10])\n",
    "    if i == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgHkMeoJdb42",
    "outputId": "1f3d172f-3f93-47ce-aa1b-e37a2afba24e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2271\n",
      "Counter({'Bach': 59, 'Beethoven': 57, 'Chopin': 34, 'Schubert': 13, 'Haydn': 11, 'Schumann': 10, 'Mozart': 6, 'Brahms': 1})\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_dataset))\n",
    "\n",
    "c = Counter()\n",
    "for p in paths:\n",
    "    c[p.split(\"/\")[0]] +=1\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191 initial pieces\n",
      "190 pieces after removing overlapping with musedata\n"
     ]
    }
   ],
   "source": [
    "# TODO: remove pieces from asap that are in Musedata\n",
    "print(len(paths), \"initial pieces\")\n",
    "paths = [p for p in paths if p!= \"Bach/Prelude/bwv_865/xml_score.musicxml\"]\n",
    "print(len(paths), \"pieces after removing overlapping with musedata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-GRCM2W3qqeW",
    "outputId": "d53c8146-8b32-43df-cd69-b7423f1ceda2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and validation lenghts:  160 29\n"
     ]
    }
   ],
   "source": [
    "# Temporary remove composer with only one piece, because they create problems with sklearn stratify\n",
    "one_piece_composers = ['Balakirev','Prokofiev','Brahms','Glinka']\n",
    "paths = [p for p in paths if p.split(\"/\")[0] not in one_piece_composers]\n",
    "\n",
    "# Divide train and validation set\n",
    "path_train, path_validation = sklearn.model_selection.train_test_split(paths, test_size=0.15,stratify=[p.split(\"/\")[0] for p in paths ])\n",
    "print(\"Train and validation lenghts: \",len(path_train),len(path_validation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "KIZ2_bX1bom5",
    "outputId": "ae8d5b50-ed4d-4376-f9d6-e96c6aa73046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Schubert', 'Beethoven', 'Mozart', 'Schumann', 'Haydn', 'Bach', 'Chopin']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 374
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#need to find a better way to visualize this\n",
    "composers = list(set([p.split(\"/\")[0] for p in paths ]))\n",
    "print(composers)\n",
    "\n",
    "train_composer = [composers.index(p.split(\"/\")[0]) for p in path_train]\n",
    "val_composer = [composers.index(p.split(\"/\")[0]) for p in path_validation]\n",
    "\n",
    "_ = plt.hist([train_composer, val_composer], label=['train', 'validation'])\n",
    "_ = plt.legend(loc='upper left')\n",
    "_ = plt.xticks(list(range(len(composers))), composers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-qaT10ApkCY"
   },
   "source": [
    "## Transform the input into a convenient format for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kEYec2TDOWvj",
    "outputId": "1b69573b-cfeb-4dc9-8882-da42f9c25537"
   },
   "outputs": [],
   "source": [
    "# Helper functions to feed the correct input into the NN \n",
    "\n",
    "PAD = \"<PAD>\"\n",
    "\n",
    "tag_to_ix = {p: accepted_pitches.index(p) for p in accepted_pitches}\n",
    "#add PADDING TAD\n",
    "tag_to_ix[PAD] = len(accepted_pitches)\n",
    "\n",
    "midi_to_ix = {m: m for m in range(12)}\n",
    "# #add PADDING TAD\n",
    "# midi_to_ix[PAD] = 12\n",
    "\n",
    "# print(midi_to_ix[1])\n",
    "# print(len(midi_to_ix))\n",
    "N_DURATION_CLASSES = 4\n",
    "\n",
    "\n",
    "class Pitch2Diatonic():\n",
    "    def __call__(self, in_seq,weights = None):\n",
    "        return [p for p in in_seq]\n",
    "\n",
    "class Diatonic2Int():\n",
    "    def __call__(self, in_seq,weights = None):\n",
    "        idxs = [tag_to_ix[w] for w in in_seq]\n",
    "        return idxs\n",
    "\n",
    "class Int2Pitch():\n",
    "    def __call__(self, in_seq):\n",
    "        return [accepted_pitches[i] for i in in_seq]\n",
    "\n",
    "class OneHotEncoder():\n",
    "    def __init__(self, alphabet_len):\n",
    "        self.alphabet_len = alphabet_len\n",
    "        \n",
    "    def __call__(self, sample,weights = None):\n",
    "        onehot = np.zeros([len(sample), self.alphabet_len])\n",
    "        tot_chars = len(sample)\n",
    "        onehot[np.arange(tot_chars), sample] = 1\n",
    "        return onehot\n",
    "    \n",
    "# class DurationOneHotEncoder():\n",
    "#     def __init__(self, pitch_alphabet_len, n_dur_class = 4):\n",
    "#         self.pitch_alphabet_len = pitch_alphabet_len\n",
    "#         self.dur_alphabet_len = n_dur_class\n",
    "        \n",
    "#     def __call__(self, sample, durs):\n",
    "#         sample = torch.tensor(sample,dtype=torch.long)\n",
    "#         onehot_pitch = torch.nn.functional.one_hot(sample,self.pitch_alphabet_len)\n",
    "#         #compute breaks in duration list\n",
    "#         if len(set(durs)) > N_DURATION_CLASSES: \n",
    "#             breaks = jenkspy.jenks_breaks(list(set(durs)), nb_class=N_DURATION_CLASSES)\n",
    "#             #quantize according to the breaks selected\n",
    "#             quantized_durations = np.digitize(durs,breaks[1:-1])\n",
    "#         elif len(set(durs)) > 2 : # in this case jenks breaks would throw an exception \n",
    "#             temp_n_classes = len(set(durs)) -1\n",
    "#             breaks = jenkspy.jenks_breaks(list(set(durs)), nb_class=temp_n_classes)\n",
    "#             # add lower classes to have the same number for all dataset\n",
    "#             for __ in range(N_DURATION_CLASSES-temp_n_classes):\n",
    "#                 breaks = [breaks[0]/2] + breaks\n",
    "#             #quantize according to the breaks selected\n",
    "#             quantized_durations = np.digitize(durs,breaks[1:-1])\n",
    "#         else: # just use custom default\n",
    "#             #quantize according to the breaks selected\n",
    "#             quantized_durations = [1 for d in durs]        \n",
    "#         quantized_durations = torch.tensor(quantized_durations,dtype=torch.long)\n",
    "#         onehot_duration = torch.nn.functional.one_hot(quantized_durations,self.dur_alphabet_len)\n",
    "#         return torch.cat([onehot_pitch,onehot_duration],1)\n",
    "\n",
    "class DurationOneHotEncoder():\n",
    "    def __init__(self, pitch_alphabet_len, n_dur_class = 4):\n",
    "        self.pitch_alphabet_len = pitch_alphabet_len\n",
    "        self.dur_alphabet_len = n_dur_class\n",
    "        \n",
    "    def __call__(self, sample, durs):\n",
    "        sample = torch.tensor(sample,dtype=torch.long)\n",
    "        onehot_pitch = torch.nn.functional.one_hot(sample,self.pitch_alphabet_len)\n",
    "        #compute breaks in duration list\n",
    "        clusters, centroids = kmeans1d.cluster(durs, 4)   \n",
    "        quantized_durations = torch.tensor(clusters,dtype=torch.long)\n",
    "        onehot_duration = torch.nn.functional.one_hot(quantized_durations,self.dur_alphabet_len)\n",
    "        return torch.cat([onehot_pitch,onehot_duration],1)\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "class ToTensorFloat():\n",
    "    def __call__(self, sample, weight = None):\n",
    "        if type(sample) is torch.Tensor:\n",
    "            return sample.float()\n",
    "        else:\n",
    "            return torch.tensor(sample,dtype=torch.float)\n",
    "\n",
    "class ToTensorLong():\n",
    "    def __call__(self, sample, weights = None):\n",
    "        if type(sample) is torch.Tensor:\n",
    "            return sample.long()\n",
    "        else:\n",
    "            return torch.tensor(sample,dtype=torch.long)\n",
    "    \n",
    "class Compose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, sample, weights):\n",
    "        for t in self.transforms:\n",
    "            sample = t(sample, weights)\n",
    "        return sample\n",
    "\n",
    "pitches_len = len(accepted_pitches)\n",
    "midinote_len = 12\n",
    "\n",
    "### Define the preprocessing pipeline\n",
    "transform_diat = Compose([Pitch2Diatonic(),Diatonic2Int(),ToTensorLong()])\n",
    "transform_chrom = Compose([DurationOneHotEncoder(len(midi_to_ix),N_DURATION_CLASSES),ToTensorFloat()])\n",
    "\n",
    "### Test if it work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jV9boYaToUs2",
    "outputId": "92bcd8d3-87a2-4d2c-8e92-4a106139f59f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1910 29\n",
      "15506\n",
      "15506\n",
      "15506\n",
      "15506\n",
      "15506\n",
      "15506\n",
      "15506\n",
      "8875\n",
      "8875\n",
      "8875\n",
      "8875\n",
      "8875\n",
      "8875\n",
      "8875\n",
      "8875\n",
      "8875\n",
      "8875\n",
      "8875\n",
      "8875\n",
      "6957\n",
      "6957\n",
      "6957\n",
      "6957\n",
      "6957\n",
      "6957\n",
      "6957\n",
      "6957\n",
      "6957\n",
      "6957\n",
      "6957\n",
      "6957\n",
      "6927\n",
      "6927\n",
      "6927\n",
      "6927\n",
      "6927\n",
      "6927\n",
      "6927\n",
      "6927\n",
      "6927\n",
      "6927\n",
      "6927\n",
      "6927\n",
      "6776\n",
      "6776\n",
      "6776\n",
      "6776\n",
      "6776\n",
      "6776\n",
      "6776\n",
      "6776\n",
      "6776\n",
      "6776\n",
      "6776\n",
      "6776\n",
      "6593\n",
      "6593\n",
      "6593\n",
      "6593\n",
      "6593\n",
      "6593\n",
      "6593\n",
      "6593\n",
      "6593\n",
      "6593\n",
      "6593\n",
      "6593\n",
      "6365\n",
      "6365\n",
      "6365\n",
      "6365\n",
      "6365\n",
      "6365\n",
      "6365\n",
      "6365\n",
      "6365\n",
      "6365\n",
      "6365\n",
      "6365\n",
      "5402\n",
      "5402\n",
      "5402\n",
      "5402\n",
      "5402\n",
      "5402\n",
      "5402\n",
      "5402\n",
      "5402\n",
      "5402\n",
      "5402\n",
      "5402\n",
      "5348\n",
      "5348\n",
      "5348\n",
      "5348\n",
      "5348\n",
      "5348\n",
      "5348\n",
      "5348\n",
      "5348\n",
      "5348\n",
      "5348\n",
      "5348\n",
      "5154\n",
      "5154\n",
      "5154\n",
      "5154\n",
      "5154\n",
      "5154\n",
      "5154\n",
      "5154\n",
      "5154\n",
      "5154\n",
      "5154\n",
      "5154\n",
      "5124\n",
      "5124\n",
      "5124\n",
      "5124\n",
      "5124\n",
      "5124\n",
      "5124\n",
      "5124\n",
      "5124\n",
      "5124\n",
      "5124\n",
      "5124\n",
      "5076\n",
      "5076\n",
      "5076\n",
      "5076\n",
      "5076\n",
      "5076\n",
      "5076\n",
      "5076\n",
      "5076\n",
      "5076\n",
      "5076\n",
      "5076\n",
      "4964\n",
      "4964\n",
      "4964\n",
      "4964\n",
      "4964\n",
      "4964\n",
      "4964\n",
      "4964\n",
      "4964\n",
      "4964\n",
      "4964\n",
      "4964\n",
      "4810\n",
      "4810\n",
      "4810\n",
      "4810\n",
      "4810\n",
      "4810\n",
      "4810\n",
      "4810\n",
      "4810\n",
      "4810\n",
      "4810\n",
      "4810\n",
      "4654\n",
      "4654\n",
      "4654\n",
      "4654\n",
      "4654\n",
      "4654\n",
      "4654\n",
      "4654\n",
      "4654\n",
      "4654\n",
      "4654\n",
      "4654\n",
      "4546\n",
      "4546\n",
      "4546\n",
      "4546\n",
      "4546\n",
      "4546\n",
      "4546\n",
      "4546\n",
      "4546\n",
      "4546\n",
      "4546\n",
      "4546\n",
      "4254\n",
      "4254\n",
      "4254\n",
      "4254\n",
      "4254\n",
      "4254\n",
      "4254\n",
      "4254\n",
      "4254\n",
      "4254\n",
      "4254\n",
      "4254\n",
      "4225\n",
      "4225\n",
      "4225\n",
      "4225\n",
      "4225\n",
      "4225\n",
      "4225\n",
      "4225\n",
      "4225\n",
      "4225\n",
      "4225\n",
      "4225\n",
      "4219\n",
      "4219\n",
      "4219\n",
      "4219\n",
      "4219\n",
      "4219\n",
      "4219\n",
      "4219\n",
      "4219\n",
      "4219\n",
      "4219\n",
      "4219\n",
      "4204\n",
      "4204\n",
      "4204\n",
      "4204\n",
      "4204\n",
      "4204\n",
      "4204\n",
      "4204\n",
      "4204\n",
      "4204\n",
      "4204\n",
      "4204\n",
      "4123\n",
      "4123\n",
      "4123\n",
      "4123\n",
      "4123\n",
      "4123\n",
      "4123\n",
      "4123\n",
      "4123\n",
      "4123\n",
      "4123\n",
      "4123\n",
      "4074\n",
      "4074\n",
      "4074\n",
      "4074\n",
      "4074\n",
      "4074\n",
      "4074\n",
      "4074\n",
      "4074\n",
      "4074\n",
      "4074\n",
      "4074\n",
      "4070\n",
      "4070\n",
      "4070\n",
      "4070\n",
      "4070\n",
      "4070\n",
      "4070\n",
      "4070\n",
      "4070\n",
      "4070\n",
      "4070\n",
      "4070\n",
      "4038\n",
      "4038\n",
      "4038\n",
      "4038\n",
      "4038\n",
      "4038\n",
      "4038\n",
      "4038\n",
      "4038\n",
      "4038\n",
      "4038\n",
      "3937\n",
      "3937\n",
      "3937\n",
      "3937\n",
      "3937\n",
      "3937\n",
      "3937\n",
      "3937\n",
      "3937\n",
      "3937\n",
      "3937\n",
      "3937\n",
      "3878\n",
      "3878\n",
      "3878\n",
      "3878\n",
      "3878\n",
      "3878\n",
      "3878\n",
      "3878\n",
      "3878\n",
      "3878\n",
      "3878\n",
      "3878\n",
      "3819\n",
      "3819\n",
      "3819\n",
      "3819\n",
      "3819\n",
      "3819\n",
      "3819\n",
      "3819\n",
      "3819\n",
      "3819\n",
      "3819\n",
      "3819\n",
      "3792\n",
      "3792\n",
      "3792\n",
      "3792\n",
      "3792\n",
      "3792\n",
      "3792\n",
      "3792\n",
      "3792\n",
      "3792\n",
      "3792\n",
      "3792\n",
      "3787\n",
      "3787\n",
      "3787\n",
      "3787\n",
      "3787\n",
      "3787\n",
      "3787\n",
      "3787\n",
      "3787\n",
      "3787\n",
      "3787\n",
      "3787\n",
      "3633\n",
      "3633\n",
      "3633\n",
      "3633\n",
      "3633\n",
      "3633\n",
      "3633\n",
      "3633\n",
      "3633\n",
      "3633\n",
      "3633\n",
      "3633\n",
      "3430\n",
      "3430\n",
      "3430\n",
      "3430\n",
      "3430\n",
      "3430\n",
      "3430\n",
      "3430\n",
      "3430\n",
      "3430\n",
      "3430\n",
      "3430\n",
      "3418\n",
      "3418\n",
      "3418\n",
      "3418\n",
      "3418\n",
      "3418\n",
      "3418\n",
      "3418\n",
      "3418\n",
      "3418\n",
      "3338\n",
      "3338\n",
      "3338\n",
      "3338\n",
      "3338\n",
      "3338\n",
      "3338\n",
      "3338\n",
      "3338\n",
      "3338\n",
      "3338\n",
      "3338\n",
      "3185\n",
      "3185\n",
      "3185\n",
      "3185\n",
      "3185\n",
      "3185\n",
      "3185\n",
      "3185\n",
      "3185\n",
      "3185\n",
      "3185\n",
      "3185\n",
      "3141\n",
      "3141\n",
      "3141\n",
      "3141\n",
      "3141\n",
      "3141\n",
      "3141\n",
      "3141\n",
      "3141\n",
      "3141\n",
      "3141\n",
      "3141\n",
      "3124\n",
      "3124\n",
      "3124\n",
      "3124\n",
      "3124\n",
      "3124\n",
      "3124\n",
      "3124\n",
      "3124\n",
      "3124\n",
      "3124\n",
      "3124\n",
      "3015\n",
      "3015\n",
      "3015\n",
      "3015\n",
      "3015\n",
      "3015\n",
      "3015\n",
      "3015\n",
      "3015\n",
      "3015\n",
      "3015\n",
      "3015\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2996\n",
      "2988\n",
      "2988\n",
      "2988\n",
      "2988\n",
      "2988\n",
      "2988\n",
      "2988\n",
      "2988\n",
      "2988\n",
      "2988\n",
      "2988\n",
      "2988\n",
      "2959\n",
      "2959\n",
      "2959\n",
      "2959\n",
      "2959\n",
      "2959\n",
      "2959\n",
      "2959\n",
      "2959\n",
      "2959\n",
      "2959\n",
      "2959\n",
      "2945\n",
      "2945\n",
      "2945\n",
      "2945\n",
      "2945\n",
      "2945\n",
      "2945\n",
      "2945\n",
      "2945\n",
      "2945\n",
      "2945\n",
      "2945\n",
      "2838\n",
      "2838\n",
      "2838\n",
      "2838\n",
      "2838\n",
      "2838\n",
      "2838\n",
      "2838\n",
      "2838\n",
      "2838\n",
      "2838\n",
      "2838\n",
      "2820\n",
      "2820\n",
      "2820\n",
      "2820\n",
      "2820\n",
      "2820\n",
      "2820\n",
      "2820\n",
      "2820\n",
      "2820\n",
      "2820\n",
      "2820\n",
      "2776\n",
      "2776\n",
      "2776\n",
      "2776\n",
      "2776\n",
      "2776\n",
      "2776\n",
      "2776\n",
      "2776\n",
      "2776\n",
      "2776\n",
      "2776\n",
      "2775\n",
      "2775\n",
      "2775\n",
      "2775\n",
      "2775\n",
      "2775\n",
      "2775\n",
      "2775\n",
      "2775\n",
      "2775\n",
      "2775\n",
      "2775\n",
      "2772\n",
      "2772\n",
      "2772\n",
      "2772\n",
      "2772\n",
      "2772\n",
      "2772\n",
      "2772\n",
      "2772\n",
      "2772\n",
      "2772\n",
      "2772\n",
      "2715\n",
      "2715\n",
      "2715\n",
      "2715\n",
      "2715\n",
      "2715\n",
      "2715\n",
      "2715\n",
      "2715\n",
      "2715\n",
      "2715\n",
      "2715\n",
      "2669\n",
      "2669\n",
      "2669\n",
      "2669\n",
      "2669\n",
      "2669\n",
      "2669\n",
      "2669\n",
      "2669\n",
      "2669\n",
      "2669\n",
      "2669\n",
      "2655\n",
      "2655\n",
      "2655\n",
      "2655\n",
      "2655\n",
      "2655\n",
      "2655\n",
      "2655\n",
      "2655\n",
      "2655\n",
      "2655\n",
      "2655\n",
      "2584\n",
      "2584\n",
      "2584\n",
      "2584\n",
      "2584\n",
      "2584\n",
      "2584\n",
      "2584\n",
      "2584\n",
      "2584\n",
      "2584\n",
      "2584\n",
      "2566\n",
      "2566\n",
      "2566\n",
      "2566\n",
      "2566\n",
      "2566\n",
      "2566\n",
      "2566\n",
      "2566\n",
      "2566\n",
      "2566\n",
      "2566\n",
      "2562\n",
      "2562\n",
      "2562\n",
      "2562\n",
      "2562\n",
      "2562\n",
      "2562\n",
      "2562\n",
      "2562\n",
      "2562\n",
      "2562\n",
      "2562\n",
      "2548\n",
      "2548\n",
      "2548\n",
      "2548\n",
      "2548\n",
      "2548\n",
      "2548\n",
      "2548\n",
      "2548\n",
      "2548\n",
      "2548\n",
      "2548\n",
      "2507\n",
      "2507\n",
      "2507\n",
      "2507\n",
      "2507\n",
      "2507\n",
      "2507\n",
      "2507\n",
      "2507\n",
      "2507\n",
      "2507\n",
      "2507\n",
      "2478\n",
      "2478\n",
      "2478\n",
      "2478\n",
      "2478\n",
      "2478\n",
      "2478\n",
      "2478\n",
      "2478\n",
      "2478\n",
      "2478\n",
      "2478\n",
      "2457\n",
      "2457\n",
      "2457\n",
      "2457\n",
      "2457\n",
      "2457\n",
      "2457\n",
      "2457\n",
      "2457\n",
      "2457\n",
      "2457\n",
      "2457\n",
      "2321\n",
      "2321\n",
      "2321\n",
      "2321\n",
      "2321\n",
      "2321\n",
      "2321\n",
      "2321\n",
      "2321\n",
      "2321\n",
      "2321\n",
      "2321\n",
      "2292\n",
      "2292\n",
      "2292\n",
      "2292\n",
      "2292\n",
      "2292\n",
      "2292\n",
      "2292\n",
      "2292\n",
      "2292\n",
      "2292\n",
      "2292\n",
      "2277\n",
      "2277\n",
      "2277\n",
      "2277\n",
      "2277\n",
      "2277\n",
      "2277\n",
      "2277\n",
      "2277\n",
      "2277\n",
      "2277\n",
      "2277\n",
      "2254\n",
      "2254\n",
      "2254\n",
      "2254\n",
      "2254\n",
      "2254\n",
      "2254\n",
      "2254\n",
      "2254\n",
      "2254\n",
      "2247\n",
      "2247\n",
      "2247\n",
      "2247\n",
      "2247\n",
      "2247\n",
      "2247\n",
      "2247\n",
      "2247\n",
      "2247\n",
      "2247\n",
      "2247\n",
      "2242\n",
      "2242\n",
      "2242\n",
      "2242\n",
      "2242\n",
      "2242\n",
      "2242\n",
      "2242\n",
      "2242\n",
      "2242\n",
      "2242\n",
      "2242\n",
      "2232\n",
      "2232\n",
      "2232\n",
      "2232\n",
      "2232\n",
      "2232\n",
      "2232\n",
      "2232\n",
      "2232\n",
      "2232\n",
      "2232\n",
      "2232\n",
      "2191\n",
      "2191\n",
      "2191\n",
      "2191\n",
      "2191\n",
      "2191\n",
      "2191\n",
      "2191\n",
      "2191\n",
      "2191\n",
      "2191\n",
      "2191\n",
      "2190\n",
      "2190\n",
      "2190\n",
      "2190\n",
      "2190\n",
      "2190\n",
      "2190\n",
      "2190\n",
      "2190\n",
      "2190\n",
      "2190\n",
      "2190\n",
      "2104\n",
      "2104\n",
      "2104\n",
      "2104\n",
      "2104\n",
      "2104\n",
      "2104\n",
      "2104\n",
      "2104\n",
      "2104\n",
      "2104\n",
      "2104\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2103\n",
      "2084\n",
      "2084\n",
      "2084\n",
      "2084\n",
      "2084\n",
      "2084\n",
      "2084\n",
      "2084\n",
      "2084\n",
      "2084\n",
      "2084\n",
      "2084\n",
      "2030\n",
      "2030\n",
      "2030\n",
      "2030\n",
      "2030\n",
      "2030\n",
      "2030\n",
      "2030\n",
      "2030\n",
      "2030\n",
      "2030\n",
      "2030\n",
      "1960\n",
      "1960\n",
      "1960\n",
      "1960\n",
      "1960\n",
      "1960\n",
      "1960\n",
      "1960\n",
      "1960\n",
      "1960\n",
      "1960\n",
      "1960\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1829\n",
      "1827\n",
      "1827\n",
      "1827\n",
      "1827\n",
      "1827\n",
      "1827\n",
      "1827\n",
      "1827\n",
      "1827\n",
      "1827\n",
      "1827\n",
      "1827\n",
      "1816\n",
      "1816\n",
      "1816\n",
      "1816\n",
      "1816\n",
      "1816\n",
      "1816\n",
      "1816\n",
      "1816\n",
      "1816\n",
      "1816\n",
      "1816\n",
      "1810\n",
      "1810\n",
      "1810\n",
      "1810\n",
      "1810\n",
      "1810\n",
      "1810\n",
      "1810\n",
      "1810\n",
      "1810\n",
      "1810\n",
      "1810\n",
      "1808\n",
      "1808\n",
      "1808\n",
      "1808\n",
      "1808\n",
      "1808\n",
      "1808\n",
      "1808\n",
      "1808\n",
      "1808\n",
      "1808\n",
      "1808\n",
      "1769\n",
      "1769\n",
      "1769\n",
      "1769\n",
      "1769\n",
      "1769\n",
      "1769\n",
      "1769\n",
      "1769\n",
      "1769\n",
      "1769\n",
      "1769\n",
      "1760\n",
      "1760\n",
      "1760\n",
      "1760\n",
      "1760\n",
      "1760\n",
      "1760\n",
      "1760\n",
      "1760\n",
      "1760\n",
      "1760\n",
      "1760\n",
      "1746\n",
      "1746\n",
      "1746\n",
      "1746\n",
      "1746\n",
      "1746\n",
      "1746\n",
      "1746\n",
      "1746\n",
      "1746\n",
      "1746\n",
      "1746\n",
      "1741\n",
      "1741\n",
      "1741\n",
      "1741\n",
      "1741\n",
      "1741\n",
      "1741\n",
      "1741\n",
      "1741\n",
      "1741\n",
      "1741\n",
      "1741\n",
      "1735\n",
      "1735\n",
      "1735\n",
      "1735\n",
      "1735\n",
      "1735\n",
      "1735\n",
      "1735\n",
      "1735\n",
      "1735\n",
      "1735\n",
      "1735\n",
      "1722\n",
      "1722\n",
      "1722\n",
      "1722\n",
      "1722\n",
      "1722\n",
      "1722\n",
      "1722\n",
      "1722\n",
      "1722\n",
      "1722\n",
      "1722\n",
      "1698\n",
      "1698\n",
      "1698\n",
      "1698\n",
      "1698\n",
      "1698\n",
      "1698\n",
      "1698\n",
      "1698\n",
      "1698\n",
      "1698\n",
      "1698\n",
      "1692\n",
      "1692\n",
      "1692\n",
      "1692\n",
      "1692\n",
      "1692\n",
      "1692\n",
      "1692\n",
      "1692\n",
      "1692\n",
      "1692\n",
      "1692\n",
      "1673\n",
      "1673\n",
      "1673\n",
      "1673\n",
      "1673\n",
      "1673\n",
      "1673\n",
      "1673\n",
      "1673\n",
      "1673\n",
      "1673\n",
      "1673\n",
      "1660\n",
      "1660\n",
      "1660\n",
      "1660\n",
      "1660\n",
      "1660\n",
      "1660\n",
      "1660\n",
      "1660\n",
      "1660\n",
      "1660\n",
      "1660\n",
      "1657\n",
      "1657\n",
      "1657\n",
      "1657\n",
      "1657\n",
      "1657\n",
      "1657\n",
      "1657\n",
      "1657\n",
      "1657\n",
      "1657\n",
      "1657\n",
      "1641\n",
      "1641\n",
      "1641\n",
      "1641\n",
      "1641\n",
      "1641\n",
      "1641\n",
      "1641\n",
      "1641\n",
      "1641\n",
      "1641\n",
      "1641\n",
      "1637\n",
      "1637\n",
      "1637\n",
      "1637\n",
      "1637\n",
      "1637\n",
      "1637\n",
      "1637\n",
      "1637\n",
      "1637\n",
      "1637\n",
      "1637\n",
      "1608\n",
      "1608\n",
      "1608\n",
      "1608\n",
      "1608\n",
      "1608\n",
      "1608\n",
      "1608\n",
      "1608\n",
      "1608\n",
      "1608\n",
      "1608\n",
      "1585\n",
      "1585\n",
      "1585\n",
      "1585\n",
      "1585\n",
      "1585\n",
      "1585\n",
      "1585\n",
      "1585\n",
      "1585\n",
      "1585\n",
      "1585\n",
      "1553\n",
      "1553\n",
      "1553\n",
      "1553\n",
      "1553\n",
      "1553\n",
      "1553\n",
      "1553\n",
      "1553\n",
      "1553\n",
      "1553\n",
      "1553\n",
      "1549\n",
      "1549\n",
      "1549\n",
      "1549\n",
      "1549\n",
      "1549\n",
      "1549\n",
      "1549\n",
      "1549\n",
      "1549\n",
      "1549\n",
      "1549\n",
      "1548\n",
      "1548\n",
      "1548\n",
      "1548\n",
      "1548\n",
      "1548\n",
      "1548\n",
      "1548\n",
      "1548\n",
      "1548\n",
      "1548\n",
      "1548\n",
      "1535\n",
      "1535\n",
      "1535\n",
      "1535\n",
      "1535\n",
      "1535\n",
      "1535\n",
      "1535\n",
      "1535\n",
      "1535\n",
      "1535\n",
      "1535\n",
      "1511\n",
      "1511\n",
      "1511\n",
      "1511\n",
      "1511\n",
      "1511\n",
      "1511\n",
      "1511\n",
      "1511\n",
      "1511\n",
      "1511\n",
      "1511\n",
      "1497\n",
      "1497\n",
      "1497\n",
      "1497\n",
      "1497\n",
      "1497\n",
      "1497\n",
      "1497\n",
      "1497\n",
      "1497\n",
      "1497\n",
      "1497\n",
      "1489\n",
      "1489\n",
      "1489\n",
      "1489\n",
      "1489\n",
      "1489\n",
      "1489\n",
      "1489\n",
      "1489\n",
      "1489\n",
      "1489\n",
      "1489\n",
      "1476\n",
      "1476\n",
      "1476\n",
      "1476\n",
      "1476\n",
      "1476\n",
      "1476\n",
      "1476\n",
      "1476\n",
      "1476\n",
      "1476\n",
      "1476\n",
      "1475\n",
      "1475\n",
      "1475\n",
      "1475\n",
      "1475\n",
      "1475\n",
      "1475\n",
      "1475\n",
      "1475\n",
      "1475\n",
      "1475\n",
      "1475\n",
      "1466\n",
      "1466\n",
      "1466\n",
      "1466\n",
      "1466\n",
      "1466\n",
      "1466\n",
      "1466\n",
      "1466\n",
      "1466\n",
      "1466\n",
      "1466\n",
      "1465\n",
      "1465\n",
      "1465\n",
      "1465\n",
      "1465\n",
      "1465\n",
      "1465\n",
      "1465\n",
      "1465\n",
      "1465\n",
      "1465\n",
      "1465\n",
      "1458\n",
      "1458\n",
      "1458\n",
      "1458\n",
      "1458\n",
      "1458\n",
      "1458\n",
      "1458\n",
      "1458\n",
      "1458\n",
      "1458\n",
      "1458\n",
      "1423\n",
      "1423\n",
      "1423\n",
      "1423\n",
      "1423\n",
      "1423\n",
      "1423\n",
      "1423\n",
      "1423\n",
      "1423\n",
      "1423\n",
      "1423\n",
      "1413\n",
      "1413\n",
      "1413\n",
      "1413\n",
      "1413\n",
      "1413\n",
      "1413\n",
      "1413\n",
      "1413\n",
      "1413\n",
      "1413\n",
      "1413\n",
      "1378\n",
      "1378\n",
      "1378\n",
      "1378\n",
      "1378\n",
      "1378\n",
      "1378\n",
      "1378\n",
      "1378\n",
      "1378\n",
      "1378\n",
      "1378\n",
      "1360\n",
      "1360\n",
      "1360\n",
      "1360\n",
      "1360\n",
      "1360\n",
      "1360\n",
      "1360\n",
      "1360\n",
      "1360\n",
      "1360\n",
      "1360\n",
      "1318\n",
      "1318\n",
      "1318\n",
      "1318\n",
      "1318\n",
      "1318\n",
      "1318\n",
      "1318\n",
      "1318\n",
      "1318\n",
      "1318\n",
      "1318\n",
      "1311\n",
      "1311\n",
      "1311\n",
      "1311\n",
      "1311\n",
      "1311\n",
      "1311\n",
      "1311\n",
      "1311\n",
      "1311\n",
      "1311\n",
      "1311\n",
      "1280\n",
      "1280\n",
      "1280\n",
      "1280\n",
      "1280\n",
      "1280\n",
      "1280\n",
      "1280\n",
      "1280\n",
      "1280\n",
      "1280\n",
      "1280\n",
      "1228\n",
      "1228\n",
      "1228\n",
      "1228\n",
      "1228\n",
      "1228\n",
      "1228\n",
      "1228\n",
      "1228\n",
      "1228\n",
      "1228\n",
      "1228\n",
      "1207\n",
      "1207\n",
      "1207\n",
      "1207\n",
      "1207\n",
      "1207\n",
      "1207\n",
      "1207\n",
      "1207\n",
      "1207\n",
      "1207\n",
      "1207\n",
      "1194\n",
      "1194\n",
      "1194\n",
      "1194\n",
      "1194\n",
      "1194\n",
      "1194\n",
      "1194\n",
      "1194\n",
      "1194\n",
      "1194\n",
      "1194\n",
      "1151\n",
      "1151\n",
      "1151\n",
      "1151\n",
      "1151\n",
      "1151\n",
      "1151\n",
      "1151\n",
      "1151\n",
      "1151\n",
      "1151\n",
      "1151\n",
      "1097\n",
      "1097\n",
      "1097\n",
      "1097\n",
      "1097\n",
      "1097\n",
      "1097\n",
      "1097\n",
      "1097\n",
      "1097\n",
      "1097\n",
      "1097\n",
      "1091\n",
      "1091\n",
      "1091\n",
      "1091\n",
      "1091\n",
      "1091\n",
      "1091\n",
      "1091\n",
      "1091\n",
      "1091\n",
      "1091\n",
      "1091\n",
      "1065\n",
      "1065\n",
      "1065\n",
      "1065\n",
      "1065\n",
      "1065\n",
      "1065\n",
      "1065\n",
      "1065\n",
      "1065\n",
      "1065\n",
      "1065\n",
      "1058\n",
      "1058\n",
      "1058\n",
      "1058\n",
      "1058\n",
      "1058\n",
      "1058\n",
      "1058\n",
      "1058\n",
      "1058\n",
      "1058\n",
      "1058\n",
      "1041\n",
      "1041\n",
      "1041\n",
      "1041\n",
      "1041\n",
      "1041\n",
      "1041\n",
      "1041\n",
      "1041\n",
      "1041\n",
      "1041\n",
      "1041\n",
      "994\n",
      "994\n",
      "994\n",
      "994\n",
      "994\n",
      "994\n",
      "994\n",
      "994\n",
      "994\n",
      "994\n",
      "994\n",
      "994\n",
      "978\n",
      "978\n",
      "978\n",
      "978\n",
      "978\n",
      "978\n",
      "978\n",
      "978\n",
      "978\n",
      "978\n",
      "978\n",
      "978\n",
      "968\n",
      "968\n",
      "968\n",
      "968\n",
      "968\n",
      "968\n",
      "968\n",
      "968\n",
      "968\n",
      "968\n",
      "968\n",
      "968\n",
      "966\n",
      "966\n",
      "966\n",
      "966\n",
      "966\n",
      "966\n",
      "966\n",
      "966\n",
      "966\n",
      "966\n",
      "966\n",
      "966\n",
      "945\n",
      "945\n",
      "945\n",
      "945\n",
      "945\n",
      "945\n",
      "945\n",
      "945\n",
      "945\n",
      "945\n",
      "945\n",
      "945\n",
      "938\n",
      "938\n",
      "938\n",
      "938\n",
      "938\n",
      "938\n",
      "938\n",
      "938\n",
      "938\n",
      "938\n",
      "938\n",
      "938\n",
      "927\n",
      "927\n",
      "927\n",
      "927\n",
      "927\n",
      "927\n",
      "927\n",
      "927\n",
      "927\n",
      "927\n",
      "927\n",
      "927\n",
      "917\n",
      "917\n",
      "917\n",
      "917\n",
      "917\n",
      "917\n",
      "917\n",
      "917\n",
      "917\n",
      "917\n",
      "917\n",
      "917\n",
      "908\n",
      "908\n",
      "908\n",
      "908\n",
      "908\n",
      "908\n",
      "908\n",
      "908\n",
      "908\n",
      "908\n",
      "908\n",
      "908\n",
      "906\n",
      "906\n",
      "906\n",
      "906\n",
      "906\n",
      "906\n",
      "906\n",
      "906\n",
      "906\n",
      "906\n",
      "906\n",
      "906\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "899\n",
      "848\n",
      "848\n",
      "848\n",
      "848\n",
      "848\n",
      "848\n",
      "848\n",
      "848\n",
      "848\n",
      "848\n",
      "848\n",
      "848\n",
      "847\n",
      "847\n",
      "847\n",
      "847\n",
      "847\n",
      "847\n",
      "847\n",
      "847\n",
      "847\n",
      "847\n",
      "847\n",
      "847\n",
      "835\n",
      "835\n",
      "835\n",
      "835\n",
      "835\n",
      "835\n",
      "835\n",
      "835\n",
      "835\n",
      "835\n",
      "835\n",
      "835\n",
      "827\n",
      "827\n",
      "827\n",
      "827\n",
      "827\n",
      "827\n",
      "827\n",
      "827\n",
      "827\n",
      "827\n",
      "827\n",
      "827\n",
      "822\n",
      "822\n",
      "822\n",
      "822\n",
      "822\n",
      "822\n",
      "822\n",
      "822\n",
      "822\n",
      "822\n",
      "822\n",
      "822\n",
      "807\n",
      "807\n",
      "807\n",
      "807\n",
      "807\n",
      "807\n",
      "807\n",
      "807\n",
      "807\n",
      "807\n",
      "807\n",
      "807\n",
      "804\n",
      "804\n",
      "804\n",
      "804\n",
      "804\n",
      "804\n",
      "804\n",
      "804\n",
      "804\n",
      "804\n",
      "804\n",
      "804\n",
      "802\n",
      "802\n",
      "802\n",
      "802\n",
      "802\n",
      "802\n",
      "802\n",
      "802\n",
      "802\n",
      "802\n",
      "802\n",
      "802\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "772\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "771\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "762\n",
      "747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747\n",
      "747\n",
      "747\n",
      "747\n",
      "747\n",
      "747\n",
      "747\n",
      "747\n",
      "747\n",
      "747\n",
      "747\n",
      "742\n",
      "742\n",
      "742\n",
      "742\n",
      "742\n",
      "742\n",
      "742\n",
      "742\n",
      "742\n",
      "742\n",
      "742\n",
      "742\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "695\n",
      "643\n",
      "643\n",
      "643\n",
      "643\n",
      "643\n",
      "643\n",
      "643\n",
      "643\n",
      "643\n",
      "643\n",
      "643\n",
      "643\n",
      "641\n",
      "641\n",
      "641\n",
      "641\n",
      "641\n",
      "641\n",
      "641\n",
      "641\n",
      "641\n",
      "641\n",
      "641\n",
      "641\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "638\n",
      "619\n",
      "619\n",
      "619\n",
      "619\n",
      "619\n",
      "619\n",
      "619\n",
      "619\n",
      "619\n",
      "619\n",
      "619\n",
      "619\n",
      "611\n",
      "611\n",
      "611\n",
      "611\n",
      "611\n",
      "611\n",
      "611\n",
      "611\n",
      "611\n",
      "611\n",
      "611\n",
      "611\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "610\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "592\n",
      "576\n",
      "576\n",
      "576\n",
      "576\n",
      "576\n",
      "576\n",
      "576\n",
      "576\n",
      "576\n",
      "576\n",
      "576\n",
      "576\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "518\n",
      "508\n",
      "508\n",
      "508\n",
      "508\n",
      "508\n",
      "508\n",
      "508\n",
      "508\n",
      "508\n",
      "508\n",
      "508\n",
      "508\n",
      "462\n",
      "462\n",
      "462\n",
      "462\n",
      "462\n",
      "462\n",
      "462\n",
      "462\n",
      "462\n",
      "462\n",
      "462\n",
      "462\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "\n",
    "class PSDataset(Dataset):\n",
    "    def __init__(self, dict_dataset, paths, transf_c, transf_d, augment_dataset, sort =False, truncate = None):\n",
    "        if sort:\n",
    "            dict_dataset = sorted(dict_dataset, key = lambda e: (len(e['midi_number'])),reverse=True)\n",
    "        if augment_dataset:\n",
    "            self.chromatic_sequences = [e[\"midi_number\"] for e in dict_dataset if e[\"original_path\"] in paths]\n",
    "            self.diatonic_sequences = [e[\"pitches\"]\n",
    "                                       for e in dict_dataset \n",
    "                                       if e[\"original_path\"] in paths]\n",
    "            self.durations = [e[\"duration\"] for e in dict_dataset if e[\"original_path\"] in paths]\n",
    "        else: #consider only non transposed pieces\n",
    "            self.chromatic_sequences = [e[\"midi_number\"] for e in dict_dataset \n",
    "                                        if (e[\"original_path\"] in paths and e[\"transposed_of\"]==\"P1\")]\n",
    "            self.diatonic_sequences = [e[\"pitches\"]\n",
    "                                       for e in dict_dataset \n",
    "                                       if (e[\"original_path\"] in paths and e[\"transposed_of\"]==\"P1\")]\n",
    "            self.durations = [e[\"duration\"] \n",
    "                              for e in dict_dataset \n",
    "                              if (e[\"original_path\"] in paths and e[\"transposed_of\"]==\"P1\")]\n",
    "        #the transformations to apply to data\n",
    "        self.transf_c = transf_c\n",
    "        self.transf_d = transf_d\n",
    "        self.truncate = truncate\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.chromatic_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chromatic_seq = self.chromatic_sequences[idx]\n",
    "        diatonic_seq = self.diatonic_sequences[idx]\n",
    "        duration_seq = self.durations[idx]\n",
    "        weights = [dur/4  if dur<=4 else 1 for dur in duration_seq  ] # limit the weights to (0,4)      \n",
    "\n",
    "        #transform\n",
    "        chromatic_seq = self.transf_c(chromatic_seq,weights)\n",
    "        diatonic_seq = self.transf_d(diatonic_seq,None)\n",
    "\n",
    "        if not self.truncate is None:\n",
    "            if len(diatonic_seq) > self.truncate:\n",
    "                chromatic_seq = chromatic_seq[0:self.truncate]\n",
    "                diatonic_seq = diatonic_seq[0:self.truncate]\n",
    "\n",
    "        #sanity check\n",
    "        assert len(chromatic_seq) == len(diatonic_seq)\n",
    "        seq_len = len(diatonic_seq)\n",
    "        \n",
    "        return chromatic_seq, diatonic_seq, seq_len\n",
    "\n",
    "train_dataset = PSDataset(dict_dataset,path_train, transform_chrom,transform_diat,True, sort = True)\n",
    "validation_dataset = PSDataset(dict_dataset,path_validation, transform_chrom,transform_diat, False)\n",
    "\n",
    "print(len(train_dataset),len(validation_dataset))\n",
    "\n",
    "\n",
    "\n",
    "# test if it works\n",
    "for chrom,diat,seq_len in train_dataset:\n",
    "#     print(chrom[0:30])\n",
    "#     print(torch.argmax(chrom[0:30],1))\n",
    "#     # print([diatonic_pitches[p.item()] for p in diat[0:30]])\n",
    "#     print([accepted_pitches[p.item()] for p in diat[0:30]])\n",
    "    print(seq_len)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAubyjw2LC8P",
    "outputId": "d6f8574f-8901-41e7-fd7a-9a0c6091eafa"
   },
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    (xx, yy, l) = zip(*batch)\n",
    "    \n",
    "    xx_pad = pad_sequence(xx)\n",
    "    yy_pad = pad_sequence(yy, padding_value=tag_to_ix[PAD])\n",
    "\n",
    "    #sort the sequences by length\n",
    "    seq_lengths, perm_idx = torch.Tensor(l).sort(0, descending=True)\n",
    "    xx_pad = xx_pad[:,perm_idx,:]\n",
    "    yy_pad = yy_pad[:,perm_idx]\n",
    "\n",
    "    return xx_pad, yy_pad, seq_lengths\n",
    "\n",
    "# data_loader = DataLoader(dataset=validation_dataset, batch_size=4, shuffle=True, collate_fn=pad_collate)\n",
    "\n",
    "\n",
    "\n",
    "# #test if it work\n",
    "# for batch in data_loader:\n",
    "#     print(batch[0].shape,batch[1].shape,batch[2])\n",
    "#     print(batch[1])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6O1OA1AjGWO-"
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QEkFBY5cUsmN"
   },
   "outputs": [],
   "source": [
    "class RNNTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\n",
    "        super(RNNTagger,self).__init__()    \n",
    "        \n",
    "        self.n_labels = n_labels\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # RNN layer. We're using a bidirectional GRU\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \n",
    "                          bidirectional=True, num_layers=n_layers)\n",
    "        \n",
    "        # Output layer. The input will be two times\n",
    "        # the RNN size since we are using a bidirectional RNN.\n",
    "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\n",
    "    \n",
    "        # Loss function that we will use during training.\n",
    "        self.loss = torch.nn.CrossEntropyLoss(reduction='mean', ignore_index = tag_to_ix[PAD])\n",
    "        \n",
    "    def compute_outputs(self, sentences,sentences_len):\n",
    "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\n",
    "        rnn_out, _ = self.rnn(sentences)\n",
    "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\n",
    "\n",
    "        out = self.top_layer(rnn_out)\n",
    "       \n",
    "        # # Find the positions where the token is a dummy padding token.\n",
    "        # pad_mask = (sentences == self.pad_word_id).float()\n",
    "\n",
    "        # # For these positions, we add some large number in the column corresponding\n",
    "        # # to the dummy padding label.\n",
    "        # out[:, :, self.pad_label_id] += pad_mask*10000\n",
    "\n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels, sentences_len):\n",
    "        # First computes the predictions, and then the loss function.\n",
    "        \n",
    "        # Compute the outputs. The shape is (max_len, n_sentences, n_labels).\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "        \n",
    "        # Flatten the outputs and the gold-standard labels, to compute the loss.\n",
    "        # The input to this loss needs to be one 2-dimensional and one 1-dimensional tensor.\n",
    "            \n",
    "        scores = scores.view(-1, self.n_labels)\n",
    "        labels = labels.view(-1)\n",
    "        return self.loss(scores, labels)\n",
    "\n",
    "    def predict(self, sentences,sentences_len):\n",
    "        # Compute the outputs from the linear units.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # Select the top-scoring labels. The shape is now (max_len, n_sentences).\n",
    "        predicted = scores.argmax(dim=2)\n",
    "\n",
    "        return [predicted[:int(l),i].cpu().numpy() for i,l in enumerate(sentences_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QE7itQ88Qx17"
   },
   "outputs": [],
   "source": [
    "class RNNCRFTagger(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\n",
    "        super(RNNCRFTagger,self).__init__()    \n",
    "        \n",
    "        self.n_labels = n_labels\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \n",
    "                          bidirectional=True, num_layers=n_layers)\n",
    "\n",
    "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\n",
    "    \n",
    "        self.crf = CRF(self.n_labels)\n",
    "        \n",
    "    def compute_outputs(self, sentences,sentences_len):\n",
    "        ## should I initialize here??\n",
    "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\n",
    "        rnn_out, _ = self.rnn(sentences)\n",
    "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\n",
    "\n",
    "        out = self.top_layer(rnn_out)\n",
    "      \n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels, sentences_len):\n",
    "        # Compute the outputs of the lower layers, which will be used as emission\n",
    "        # scores for the CRF.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # We return the loss value. The CRF returns the log likelihood, but we return \n",
    "        # the *negative* log likelihood as the loss value.            \n",
    "        # PyTorch's optimizers *minimize* the loss, while we want to *maximize* the\n",
    "        # log likelihood.\n",
    "\n",
    "        pad_mask = torch.arange(max(sentences_len))[:, None] < sentences_len[None, :]\n",
    "        pad_mask = pad_mask.byte().to(device)\n",
    "        return -self.crf(scores, labels, mask = pad_mask )\n",
    "            \n",
    "    def predict(self, sentences,sentences_len):\n",
    "        # Compute the emission scores, as above.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # Apply the Viterbi algorithm to get the predictions. This implementation returns\n",
    "        # the result as a list of lists (not a tensor), corresponding to a matrix\n",
    "        # of shape (n_sentences, max_len).\n",
    "        pad_mask = torch.arange(max(sentences_len))[:, None] < sentences_len[None, :]\n",
    "        pad_mask = pad_mask.byte().to(device)\n",
    "        return self.crf.decode(scores,mask = pad_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNAttentionTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\n",
    "        super(RNNAttentionTagger,self).__init__()    \n",
    "        \n",
    "        self.n_labels = n_labels\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # RNN layer. We're using a bidirectional GRU\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \n",
    "                          bidirectional=True, num_layers=n_layers)\n",
    "        \n",
    "        # Output layer. The input will be two times\n",
    "        # the RNN size since we are using a bidirectional RNN.\n",
    "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\n",
    "    \n",
    "        # Loss function that we will use during training.\n",
    "        self.loss = torch.nn.CrossEntropyLoss(reduction='mean',ignore_index = tag_to_ix[PAD])\n",
    "        \n",
    "        # attention function\n",
    "        # TODO : set right parameters\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        \n",
    "    def compute_outputs(self, sentences,sentences_len):\n",
    "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\n",
    "        rnn_out, _ = self.rnn(sentences)\n",
    "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\n",
    "        # use attention\n",
    "        attn_applied = self.attention(rnn_out,rnn_out,sentences_len)\n",
    "        \n",
    "        out = self.top_layer(attn_applied) #maybe remove this one?\n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels, sentences_len):\n",
    "        # First computes the predictions, and then the loss function.\n",
    "        \n",
    "        # Compute the outputs. The shape is (max_len, n_sentences, n_labels).\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "        \n",
    "        # Flatten the outputs and the gold-standard labels, to compute the loss.\n",
    "        # The input to this loss needs to be one 2-dimensional and one 1-dimensional tensor.\n",
    "            \n",
    "        scores = scores.view(-1, self.n_labels)\n",
    "        labels = labels.view(-1)\n",
    "        return self.loss(scores, labels)\n",
    "\n",
    "    def predict(self, sentences,sentences_len):\n",
    "        # Compute the outputs from the linear units.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # Select the top-scoring labels. The shape is now (max_len, n_sentences).\n",
    "        predicted = scores.argmax(dim=2)\n",
    "\n",
    "        return [predicted[:int(l),i].cpu().numpy() for i,l in enumerate(sentences_len)]\n",
    "    \n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention,self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.W = torch.nn.Parameter(torch.FloatTensor(\n",
    "            hidden_dim, hidden_dim).uniform_(-0.1, 0.1))\n",
    "\n",
    "    def forward(self,\n",
    "                query, # [seq_len, batch, hidden_dim]\n",
    "                values, # [seq_len, batch, hidden_dim]\n",
    "                sentences_len\n",
    "               ):\n",
    "        weights = self._get_weights(query, values) # [batch,seq_length,hidden_dim]\n",
    "        # mask the weights\n",
    "        inverted_pad_mask = torch.arange(max(sentences_len))[None,:] > sentences_len[:,None]\n",
    "        inverted_pad_mask = (inverted_pad_mask.float()*(-10000)).unsqueeze(1).to(device)\n",
    "#         print(weights.shape,inverted_pad_mask.shape )\n",
    "        #apply the mask\n",
    "        weights = weights - inverted_pad_mask\n",
    "        \n",
    "        weights = torch.nn.functional.softmax(weights, dim=-1)\n",
    "        \n",
    "        out = torch.transpose((weights @ torch.transpose(values,0,1)),0,1)\n",
    "#         print(\"ATT out shape\", out.shape)\n",
    "        return out # [seq_len,batch,encoder_dim]\n",
    "\n",
    "    def _get_weights(self,\n",
    "        query: torch.Tensor,  # [decoder_dim]\n",
    "        values: torch.Tensor, # [seq_length, encoder_dim]\n",
    "    ):\n",
    "        #transpose to batch first to correctly handle batch multiplications\n",
    "#         print(\"shape\",query.shape,self.W.shape, values.shape)\n",
    "        query,values = torch.transpose(query,0,1),torch.transpose(values,0,1)\n",
    "#         print(\"shape\",query.shape,self.W.shape, values.shape)\n",
    "#         print(\"stape values.t\", torch.transpose(values,1,2).shape)\n",
    "        weights = query @ self.W @ torch.transpose(values,1,2)  # [seq_length]\n",
    "#         print(\"out att shape\", weights.shape)\n",
    "        return weights/np.sqrt(self.hidden_dim)  # [seq_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNMultAttentionTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\n",
    "        super(RNNMultAttentionTagger,self).__init__()    \n",
    "        \n",
    "        self.n_labels = n_labels\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # RNN layer. We're using a bidirectional GRU\n",
    "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \n",
    "                          bidirectional=True, num_layers=n_layers)\n",
    "        \n",
    "        # Output layer. The input will be two times\n",
    "        # the RNN size since we are using a bidirectional RNN.\n",
    "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\n",
    "    \n",
    "        # Loss function that we will use during training.\n",
    "        self.loss = torch.nn.CrossEntropyLoss(reduction='mean',ignore_index = tag_to_ix[PAD])\n",
    "        \n",
    "        # attention function\n",
    "        self.attention = torch.nn.MultiheadAttention(hidden_dim,num_heads= 1)\n",
    "        \n",
    "    def compute_outputs(self, sentences,sentences_len):\n",
    "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\n",
    "        rnn_out, _ = self.rnn(sentences)\n",
    "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\n",
    "        # compute padding mask (True when padded, ignore True)\n",
    "        inverted_pad_mask = torch.arange(max(sentences_len))[None,:] > sentences_len[:,None]\n",
    "        \n",
    "        # use attention\n",
    "        attn_applied, _ = self.attention(rnn_out,rnn_out,rnn_out,key_padding_mask = inverted_pad_mask.to(device))\n",
    "        \n",
    "        out = self.top_layer(attn_applied)\n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels, sentences_len):\n",
    "        # First computes the predictions, and then the loss function.\n",
    "        \n",
    "        # Compute the outputs. The shape is (max_len, n_sentences, n_labels).\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "        \n",
    "        # Flatten the outputs and the gold-standard labels, to compute the loss.\n",
    "        # The input to this loss needs to be one 2-dimensional and one 1-dimensional tensor.\n",
    "            \n",
    "        scores = scores.view(-1, self.n_labels)\n",
    "        labels = labels.view(-1)\n",
    "        return self.loss(scores, labels)\n",
    "\n",
    "    def predict(self, sentences,sentences_len):\n",
    "        # Compute the outputs from the linear units.\n",
    "        scores = self.compute_outputs(sentences,sentences_len)\n",
    "\n",
    "        # Select the top-scoring labels. The shape is now (max_len, n_sentences).\n",
    "        predicted = scores.argmax(dim=2)\n",
    "\n",
    "        return [predicted[:int(l),i].cpu().numpy() for i,l in enumerate(sentences_len)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXixmVQfvw8T"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "3m_nj4HCuCe1"
   },
   "outputs": [],
   "source": [
    "# TODO: search over the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "uAMSIlw0AJb6"
   },
   "outputs": [],
   "source": [
    "def training_loop(model, optimizer, train_dataloader, val_dataloader, n_epochs):\n",
    "    history = defaultdict(list)  \n",
    "    for i_epoch in range(1,n_epochs +1):\n",
    "        t0 = time.time()\n",
    "        loss_sum = 0\n",
    "        accuracy_sum = 0\n",
    "        model.train()\n",
    "        for seqs, targets, lens in train_dataloader: #seqs, targets, lens are batches\n",
    "            seqs, targets = seqs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "#             print(\"input seq shape:\",seqs.shape)\n",
    "\n",
    "#             loss = model(seqs,targets,lens) / sum(lens) #normalize for the number of symbol considered (without padding)\n",
    "            loss = model(seqs,targets,lens)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "            predicted = model.predict(seqs,lens)\n",
    "            for i,p in enumerate(predicted):\n",
    "                acc= accuracy_score(p,targets[:,i][:len(p)].cpu()) #compute the accuracy without considering the padding\n",
    "                accuracy_sum += acc/len(lens) #normalize according to the number of sequences in the batch\n",
    "\n",
    "        train_loss = loss_sum/len(train_dataloader)\n",
    "        train_accuracy = accuracy_sum/len(train_dataloader) #normalize according to the number of batches\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_accuracy\"].append(train_accuracy)\n",
    "\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        model.eval()\n",
    "        all_predicted = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for seqs,targets, lens in val_dataloader:\n",
    "                # Predict the model's output on a batch\n",
    "                predicted = model.predict(seqs.to(device),lens)                   \n",
    "                # Update the lists that will be used to compute the accuracy\n",
    "                for i,p in enumerate(predicted):\n",
    "                    all_predicted.append(torch.Tensor(p))\n",
    "                    all_targets.append(targets[0:int(lens[i]),i])\n",
    "                \n",
    "        # Compute the overall accuracy for the validation set\n",
    "        val_accuracy = accuracy_score(torch.cat(all_predicted),torch.cat(all_targets))\n",
    "        history[\"val_accuracy\"].append(val_accuracy)\n",
    "\n",
    "#         save the model\n",
    "        torch.save(model, \"./models/temp/model_temp_epoch{}.pkl\".format(i_epoch))\n",
    "#         files.download(\"model_temp_epoch{}.pkl\".format(i_epoch))\n",
    "\n",
    "    \n",
    "        t1 = time.time()\n",
    "        print(f'Epoch {i_epoch}: train loss = {train_loss:.4f}, train_accuracy: {train_accuracy:.4f},val_accuracy: {val_accuracy:.4f}, time = {t1-t0:.4f}')\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# del train_dataset\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "2g2st8znpGW_",
    "outputId": "fe232e42-e270-4f5d-9bd8-718bba5e7151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device: cuda\n",
      "Epoch 1: train loss = 2.8723, train_accuracy: 0.0988,val_accuracy: 0.2082, time = 148.2217\n",
      "Epoch 2: train loss = 1.7630, train_accuracy: 0.3814,val_accuracy: 0.9071, time = 146.7603\n",
      "Epoch 3: train loss = 1.2579, train_accuracy: 0.4763,val_accuracy: 0.9138, time = 149.0810\n",
      "Epoch 4: train loss = 1.1895, train_accuracy: 0.4804,val_accuracy: 0.8542, time = 150.1754\n",
      "Epoch 5: train loss = 1.1735, train_accuracy: 0.4855,val_accuracy: 0.9163, time = 149.4520\n",
      "Epoch 6: train loss = 1.1775, train_accuracy: 0.4891,val_accuracy: 0.8839, time = 147.5374\n",
      "Epoch 7: train loss = 1.1635, train_accuracy: 0.4853,val_accuracy: 0.9189, time = 149.2480\n",
      "Epoch 8: train loss = 1.1304, train_accuracy: 0.4895,val_accuracy: 0.8953, time = 149.8703\n",
      "Epoch 9: train loss = 1.1453, train_accuracy: 0.4906,val_accuracy: 0.9216, time = 148.4011\n",
      "Epoch 10: train loss = 1.1400, train_accuracy: 0.4936,val_accuracy: 0.9113, time = 148.3447\n",
      "Epoch 11: train loss = 1.1532, train_accuracy: 0.4918,val_accuracy: 0.9208, time = 149.0150\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "n_epochs = 40\n",
    "HIDDEN_DIM = 96\n",
    "LEARNING_WEIGHT = 0.05\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 2\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "train_dataset = PSDataset(dict_dataset,path_train, transform_chrom,transform_diat,True,sort=True, truncate = None)\n",
    "validation_dataset = PSDataset(dict_dataset,path_validation, transform_chrom,transform_diat, False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,collate_fn=pad_collate)\n",
    "val_dataloader = DataLoader(validation_dataset, batch_size=1, shuffle=False,collate_fn=pad_collate)\n",
    "\n",
    "# model = torch.load(\"./models/temp/model_temp_epoch30-to_restart.pkl\")\n",
    "# model = RNNTagger(len(midi_to_ix)+N_DURATION_CLASSES,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "# model = RNNCRFTagger(len(midi_to_ix)+number_duration_classes,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "model = RNNAttentionTagger(len(midi_to_ix)+N_DURATION_CLASSES,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "# model = RNNMultAttentionTagger(len(midi_to_ix)+N_DURATION_CLASSES,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_WEIGHT, momentum = MOMENTUM,weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "history = training_loop(model,optimizer,train_dataloader,val_dataloader, n_epochs)\n",
    "\n",
    "# After the final evaluation, we print more detailed evaluation statistics,\n",
    "plt.plot(history['train_loss'])\n",
    "plt.plot(history['train_accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.legend(['training loss', 'training accuracy', 'validation_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy:  0.9249589391082182 at epoch 37\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc224afca20>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 251,
       "width": 372
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#find the best working model on the accuracy\n",
    "max_accuracy = np.max(history['val_accuracy'])\n",
    "best_epoch = np.argmax(history['val_accuracy'])\n",
    "print(\"Best validation accuracy: \",max_accuracy, \"at epoch\",best_epoch)\n",
    "\n",
    "plt.plot(history['train_loss'])\n",
    "plt.plot(history['train_accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.legend(['training loss', 'training accuracy', 'validation_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "tTv2BrGbvSHh",
    "outputId": "801ff32d-24dc-4434-a436-17d9ca832214"
   },
   "outputs": [],
   "source": [
    "# torch.save(model, \"./models/model_asap_crf200dur.pkl\")\n",
    "# files.download(\"model_asap_crf300.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXcmLpCKt28l"
   },
   "source": [
    "## Test on Mdata dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./models/model_RNNTagger9736.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "BacUqgD5usGL"
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "with open(Path(basepath,'./datasets/musedata_noisy.pkl'), 'rb') as fid:\n",
    "     full_mdata_dict_dataset = pickle.load( fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgaUwW2fuwg0",
    "outputId": "89fc5f7d-884a-4ee6-fc34-b3d512f0c4c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216 different pieces\n",
      "Average number of notes:  907.2777777777778\n"
     ]
    }
   ],
   "source": [
    "mdata_paths = list(set([e[\"original_path\"] for e in full_mdata_dict_dataset ]))\n",
    "\n",
    "# # remove the symbphony No.100 from Haydn because of the enharmonic transposition\n",
    "# paths.remove(\"datasets\\\\opnd\\\\haydndoversyms-10004m.opnd-m\")\n",
    "\n",
    "# print(paths)\n",
    "print(len(mdata_paths), \"different pieces\")\n",
    "print(\"Average number of notes: \", np.mean([len(e[\"midi_number\"]) for e in full_mdata_dict_dataset ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "f-Fg6gJKvNLt"
   },
   "outputs": [],
   "source": [
    "mdata_dataset = PSDataset(full_mdata_dict_dataset,mdata_paths, transform_chrom,transform_diat,False)\n",
    "mdata_dataloader  = DataLoader(mdata_dataset,  batch_size=1, shuffle=False, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ml905Mtdvj-T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "all_inputs = []\n",
    "all_outputs = []\n",
    "all_targets = []\n",
    "model.eval() # Evaluation mode (e.g. disable dropout)\n",
    "with torch.no_grad(): # Disable gradient tracking\n",
    "    for seqs, targets,lens in mdata_dataloader:\n",
    "        # Move data to device\n",
    "        seqs = seqs.to(device)\n",
    "\n",
    "        # Predict the model's output on a batch.\n",
    "        predicted = model.predict(seqs,lens)                   \n",
    "        # Update the evaluation statistics.\n",
    "        for i,p in enumerate(predicted):\n",
    "            all_inputs.append(torch.argmax(seqs[0:int(lens[i]),i,:].cpu(),1).numpy())\n",
    "            all_outputs.append(torch.Tensor(p))\n",
    "            all_targets.append(targets[0:int(lens[i]),i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OsefdSHxvrWy",
    "outputId": "33785b90-5e03-4a6d-86dd-92b6b763a505"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hay', 'han', 'bac', 'bee', 'tel', 'moz', 'viv', 'cor']\n"
     ]
    }
   ],
   "source": [
    "# Divide accuracy according to author\n",
    "authors = []\n",
    "\n",
    "for sequence in all_inputs:\n",
    "    author = [e[\"original_path\"].split(\"\\\\\")[-1][:3] for e in full_mdata_dict_dataset\n",
    "              if len(e[\"midi_number\"]) == len(sequence) and\n",
    "              list(e[\"midi_number\"]) ==list(sequence) ]\n",
    "    # assert len(author) == 1\n",
    "    authors.append(author[0])\n",
    "\n",
    "considered_authors = list(set(authors))\n",
    "print(considered_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgNt_yG7vrfd",
    "outputId": "8473393f-dac6-4930-9d9e-da9c1046f1ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hay': 243, 'han': 7, 'bac': 28, 'bee': 212, 'tel': 21, 'moz': 119, 'viv': 55, 'cor': 9}\n",
      "{'hay': 0.9900775826868109, 'han': 0.9997142857142857, 'bac': 0.9988573760457049, 'bee': 0.991344465765729, 'tel': 0.9991428571428571, 'moz': 0.9951416673471054, 'viv': 0.9977548271216884, 'cor': 0.9996325480749602}\n",
      "{'hay': 24490, 'han': 24500, 'bac': 24505, 'bee': 24493, 'tel': 24500, 'moz': 24494, 'viv': 24497, 'cor': 24493}\n",
      "Total errors : 694\n"
     ]
    }
   ],
   "source": [
    "errors_per_author = {}\n",
    "accuracy_per_author = {}\n",
    "notes_per_author = {}\n",
    "for ca in considered_authors:\n",
    "    # ca_inputs = torch.cat([all_inputs[i] for i,a in enumerate(authors) if a == ca])\n",
    "    ca_outputs = torch.cat([all_outputs[i] for i,a in enumerate(authors) if a == ca])\n",
    "    ca_targets = torch.cat([all_targets[i] for i,a in enumerate(authors) if a == ca])\n",
    "    # print(ca_inputs.shape,ca_outputs.shape,ca_targets.shape,ca_predicted_pitches.shape)\n",
    "    ca_acc = accuracy_score(ca_outputs,ca_targets)\n",
    "    accuracy_per_author[ca] = float(ca_acc)\n",
    "    errors_per_author[ca] = int(len(ca_targets) - sum(torch.eq(ca_outputs,ca_targets)))\n",
    "    notes_per_author[ca] = len(ca_targets)\n",
    "\n",
    "print(errors_per_author)\n",
    "print(accuracy_per_author)\n",
    "print(notes_per_author)\n",
    "print(\"Total errors :\", sum([e for e in errors_per_author.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5s0d56evrje"
   },
   "source": [
    "### Best accuracy for now\n",
    "for now best accuracy is with  no CRF (but considering durations) n_epochs = 20\n",
    "n_epochs = 20\n",
    "HIDDEN_DIM = 96\n",
    "LEARNING_WEIGHT = 0.05\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 8\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "duration_delimiter = automatic calculated\n",
    "\n",
    "Model available in: \"model_RNNTagger9736.pkl\"\n",
    "\n",
    "Epoch 16: train loss = 0.2798, train_accuracy: 0.9245,val_accuracy: 0.9736, time = 78.1199\n",
    "Trained on all dataset\n",
    "\n",
    "\n",
    "{'moz': 65, 'bac': 40, 'bee': 88, 'cor': 6, 'han': 8, 'viv': 63, 'tel': 21, 'hay': 262}\n",
    "{'moz': 0.9973462888870744, 'bac': 0.9983676800652928, 'bee': 0.9964071367329441, 'cor': 0.9997550320499735, 'han': 0.9996734693877551, 'viv': 0.9974282565212067, 'tel': 0.9991428571428571, 'hay': 0.9893017558187015}\n",
    "{'moz': 24494, 'bac': 24505, 'bee': 24493, 'cor': 24493, 'han': 24500, 'viv': 24497, 'tel': 24500, 'hay': 24490}\n",
    "Total errors : 553\n",
    "\n",
    "This win by far against ps13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVvP1eH8vrl3"
   },
   "source": [
    "### Best accuracy with CRF\n",
    "n_epochs = 20\n",
    "HIDDEN_DIM = 96\n",
    "LEARNING_WEIGHT = 1\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "model = RNNCRFTagger(len(midi_to_ix)+len(duration_delimiter)+2,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\n",
    "\n",
    "Model available in: \"\"./models/model_temp_CRFacc9548.pkl\"\"\n",
    "accuracy on validation set 0.9548586557910835\n",
    "Trained on all asap dataset\n",
    "\n",
    "{'viv': 36, 'tel': 41, 'bee': 185, 'bac': 101, 'han': 44, 'cor': 14, 'moz': 131, 'hay': 376}\n",
    "{'viv': 0.9985304322978323, 'tel': 0.9983265306122449, 'bee': 0.9924468215408484, 'bac': 0.9958783921648643, 'han': 0.9982040816326531, 'cor': 0.9994284081166047, 'moz': 0.9946517514493345, 'hay': 0.9846467946100449}\n",
    "{'viv': 24497, 'tel': 24500, 'bee': 24493, 'bac': 24505, 'han': 24500, 'cor': 24493, 'moz': 24494, 'hay': 24490}\n",
    "Total errors : 928\n",
    "\n",
    "Still win against ps13"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOTDh55Hh2OWCo66dGc+SES",
   "include_colab_link": true,
   "name": "rnncrf_pitch_spelling",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
