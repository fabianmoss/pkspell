{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pitch_spelling_musedata_crf_batch.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMCEsIn3Sd8/Avl0eOsZ0ni",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fosfrancesco/pitch-spelling/blob/main/pitch_spelling_rnncrf_asap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fifMg_hxNSOg",
        "outputId": "bab3991b-59b2-47e8-80b8-0263091067b4"
      },
      "source": [
        "! pip install --upgrade pytorch-crf"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-crf\n",
            "  Downloading https://files.pythonhosted.org/packages/96/7d/4c4688e26ea015fc118a0327e5726e6596836abce9182d3738be8ec2e32a/pytorch_crf-0.7.2-py3-none-any.whl\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsciybUBNkur"
      },
      "source": [
        "import music21 as m21\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import sklearn\r\n",
        "import sklearn.model_selection\r\n",
        "import pickle\r\n",
        "from google.colab import files\r\n",
        "\r\n",
        "from pathlib import Path\r\n",
        "import json\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import sklearn.model_selection\r\n",
        "import sklearn\r\n",
        "import music21 as m21\r\n",
        "from collections import Counter\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torchvision import transforms\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from torch.utils.data import random_split\r\n",
        "from torch.nn.utils.rnn import pad_sequence\r\n",
        "from torchcrf import CRF\r\n",
        "import torchtext\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "from tqdm import tqdm, tqdm_notebook, notebook\r\n",
        "from google.colab import files\r\n",
        "import pickle\r\n",
        "\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "import time\r\n",
        "\r\n",
        "from collections import defaultdict, Counter\r\n",
        "# import optuna"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Naq6UG5jRbyK"
      },
      "source": [
        "# RNN-CRF for Pitch Spelling\r\n",
        "\r\n",
        "Dataset: different authors from ASAP collection\r\n",
        "Challenges:\r\n",
        "- extremely long sequences\r\n",
        "- small dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mHJvrZ2Wo_e",
        "outputId": "992c3568-a09e-47b6-87c7-4324612aa86b"
      },
      "source": [
        "pitches_dict = {\r\n",
        "    0 : [\"C\",\"B#\",\"D--\"], # nn.Linear(input_size+context_size, 3)\r\n",
        "    1 : [\"C#\",\"B##\",\"D-\"], # nn.Linear(input_size+context_size, 2)\r\n",
        "    2 : [\"D\",\"C##\",\"E--\"], # nn.Linear(input_size+context_size, 3)\r\n",
        "    3 : [\"D#\",\"E-\",\"F--\"],\r\n",
        "    4 : [\"E\",\"D##\",\"F-\"],\r\n",
        "    5 : [\"F\",\"E#\",\"G--\"],\r\n",
        "    6 : [\"F#\",\"E##\",\"G-\"],\r\n",
        "    7 : [\"G\",\"F##\",\"A--\"],\r\n",
        "    8 : [\"G#\",\"A-\"],\r\n",
        "    9 : [\"A\",\"G##\",\"B--\"],\r\n",
        "    10 : [\"A#\",\"B-\",\"C--\"],\r\n",
        "    11 : [\"B\",\"A##\",\"C-\"]\r\n",
        "}\r\n",
        "\r\n",
        "accepted_pitches = [ii for i in pitches_dict.values() for ii in i]\r\n",
        "print([e for e in enumerate(accepted_pitches)])\r\n",
        "\r\n",
        "double_acc_pitches = [ii for i in pitches_dict.values() for ii in i if ii.endswith(\"##\") or  ii.endswith(\"--\") ]\r\n",
        "print(double_acc_pitches)\r\n",
        "\r\n",
        "def score2midi_numbers(score):\r\n",
        "  return [p.midi%12 for n in score.flat.notes for p in n.pitches]\r\n",
        "\r\n",
        "def score2pitches(score):\r\n",
        "  return [p.name for n in score.flat.notes for p in n.pitches]\r\n",
        "\r\n",
        "interval_dict = {\r\n",
        "    0 : [\"P1\",\"d2\",\"A7\"], \r\n",
        "    1 : [\"m2\",\"A1\"], \r\n",
        "    2 : [\"M2\",\"d3\",\"AA1\"], \r\n",
        "    3 : [\"m3\",\"A2\"],\r\n",
        "    4 : [\"M3\",\"d4\",\"AA2\"],\r\n",
        "    5 : [\"P4\",\"A3\"],\r\n",
        "    6 : [\"d5\",\"A4\"],\r\n",
        "    7 : [\"P5\",\"d6\",\"AA4\"],\r\n",
        "    8 : [\"m6\",\"A5\"],\r\n",
        "    9 : [\"M6\",\"d7\",\"AA5\"],\r\n",
        "    10 : [\"m7\",\"A6\"],\r\n",
        "    11 : [\"M7\",\"d1\",\"AA6\"]\r\n",
        "}\r\n",
        "\r\n",
        "accepted_intervals = [ii for i in interval_dict.values() for ii in i]\r\n",
        "print([e for e in enumerate(accepted_intervals)])\r\n",
        "\r\n",
        "def transp_score(score):\r\n",
        "    \"\"\" For each input return len(accepted_intervals) transposed scores\"\"\"\r\n",
        "    return [score.transpose(interval) for interval in accepted_intervals]\r\n",
        "\r\n",
        "def smart_transp_score(score):\r\n",
        "    \"\"\" For each chromatic interval chose the interval that lead to the smallest number of accidentals\"\"\"\r\n",
        "    scores = []\r\n",
        "    for chromatic_int in interval_dict.keys():\r\n",
        "        temp_scores = []\r\n",
        "        temp_acc_number = []\r\n",
        "        for diat_interval in interval_dict[chromatic_int]:\r\n",
        "            new_score = score.transpose(diat_interval)\r\n",
        "            temp_scores.append(new_score)\r\n",
        "            temp_acc_number.append(sum([pitch.count(\"#\") + pitch.count(\"-\") for pitch in score2pitches(new_score)]))\r\n",
        "            # print(\"choice:\", [note.name for note in temp_scores[-1].flat.notes][0:10],\"acc:\",temp_acc_number[-1] )\r\n",
        "        #keep only the one with the lowest number of accidentals\r\n",
        "        min_index = np.argmin(temp_acc_number)\r\n",
        "        # print(\"preferred the number\", min_index)\r\n",
        "        scores.append(temp_scores[min_index])\r\n",
        "    return scores\r\n",
        "\r\n",
        "def acc_simple_enough(score,accepted_ratio = 0.2 ):\r\n",
        "    pitches = score2pitches(score)\r\n",
        "    double_acc = sum(el in double_acc_pitches for el in pitches)\r\n",
        "    if double_acc/len(pitches) < accepted_ratio:\r\n",
        "        return True\r\n",
        "    else:\r\n",
        "        return False\r\n",
        "\r\n",
        "def argmax(vec):\r\n",
        "    # return the argmax as a python int\r\n",
        "    _, idx = torch.max(vec, 1)\r\n",
        "    return idx.item()\r\n",
        "\r\n",
        "\r\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\r\n",
        "def log_sum_exp(vec):\r\n",
        "    max_score = vec[0, argmax(vec)]\r\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\r\n",
        "    return max_score + \\\r\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\r\n",
        "\r\n",
        "\r\n",
        "diatonic_pitches = [\"C\",\"D\", \"E\", \"F\", \"G\", \"A\", \"B\"]\r\n",
        "\r\n",
        "# #test acc_simple_enough()\r\n",
        "# score = m21.converter.parse(paths[356])\r\n",
        "# scores = smart_transp_score(score)\r\n",
        "# #delete the pieces with non accepted pitches (e.g. triple sharps)\r\n",
        "# scores = [s for s in scores if all(pitch in accepted_pitches for pitch in score2pitches(s))]\r\n",
        "# for s in scores:\r\n",
        "#     print(s.parts[0].flat.getElementsByClass(m21.key.KeySignature)[0], \"simple enough:\", acc_simple_enough(s))\r\n",
        "#     print([n.name for n in s.flat.notes])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 'C'), (1, 'B#'), (2, 'D--'), (3, 'C#'), (4, 'B##'), (5, 'D-'), (6, 'D'), (7, 'C##'), (8, 'E--'), (9, 'D#'), (10, 'E-'), (11, 'F--'), (12, 'E'), (13, 'D##'), (14, 'F-'), (15, 'F'), (16, 'E#'), (17, 'G--'), (18, 'F#'), (19, 'E##'), (20, 'G-'), (21, 'G'), (22, 'F##'), (23, 'A--'), (24, 'G#'), (25, 'A-'), (26, 'A'), (27, 'G##'), (28, 'B--'), (29, 'A#'), (30, 'B-'), (31, 'C--'), (32, 'B'), (33, 'A##'), (34, 'C-')]\n",
            "['D--', 'B##', 'C##', 'E--', 'F--', 'D##', 'G--', 'E##', 'F##', 'A--', 'G##', 'B--', 'C--', 'A##']\n",
            "[(0, 'P1'), (1, 'd2'), (2, 'A7'), (3, 'm2'), (4, 'A1'), (5, 'M2'), (6, 'd3'), (7, 'AA1'), (8, 'm3'), (9, 'A2'), (10, 'M3'), (11, 'd4'), (12, 'AA2'), (13, 'P4'), (14, 'A3'), (15, 'd5'), (16, 'A4'), (17, 'P5'), (18, 'd6'), (19, 'AA4'), (20, 'm6'), (21, 'A5'), (22, 'M6'), (23, 'd7'), (24, 'AA5'), (25, 'm7'), (26, 'A6'), (27, 'M7'), (28, 'd1'), (29, 'AA6')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrZ0BwLEj2Gp",
        "outputId": "2f14d2fd-9f46-4b42-92a4-f6e32866c581"
      },
      "source": [
        "!git clone https://github.com/fosfrancesco/pitch-spelling.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pitch-spelling'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 39 (delta 14), reused 14 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (39/39), done.\n",
            "Checking out files: 100% (11/11), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaINjDS2kpxE"
      },
      "source": [
        "basepath = \"/content/pitch-spelling\" #to change if running locally\r\n",
        "\r\n",
        "# load the asap datasets\r\n",
        "with open(Path(basepath,'datasets','baroque_asap.pkl'), 'rb') as fid:\r\n",
        "     dataset_baroque = pickle.load( fid)\r\n",
        "\r\n",
        "with open(Path(basepath,'datasets','classical_asap.pkl'), 'rb') as fid:\r\n",
        "     dataset_classical = pickle.load( fid)\r\n",
        "\r\n",
        "# with open(Path(basepath,'datasets','romantic_asap.pkl'), 'rb') as fid:\r\n",
        "#      dataset_romantic = pickle.load( fid)\r\n",
        "\r\n",
        "# merge the two files together\r\n",
        "# full_dict_dataset = dataset_baroque + dataset_classical + dataset_romantic\r\n",
        "full_dict_dataset = dataset_baroque + dataset_classical"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYQdkJAiTS6_",
        "outputId": "1bf56b0a-ce96-45e0-dd50-c3757b0c3a4a"
      },
      "source": [
        "paths = list(set([e[\"original_path\"] for e in full_dict_dataset ]))\r\n",
        "\r\n",
        "# remove the symbphony No.100 from Haydn because of the enharmonic transposition\r\n",
        "# paths.remove(\"datasets\\\\opnd\\\\haydndoversyms-10004m.opnd-m\")\r\n",
        "\r\n",
        "# print(paths)\r\n",
        "print(len(paths), \"different pieces\")\r\n",
        "print(\"Average number of notes: \", np.mean([len(e[\"midi_number\"]) for e in full_dict_dataset ]))\r\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "133 different pieces\n",
            "Average number of notes:  1942.5449633346198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oign7EZ9BSX4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3803073-b88f-46ee-bb70-898de0ea0202"
      },
      "source": [
        "# choose only one enharmonic version for each chromatic interval for each piece\r\n",
        "dict_dataset = []\r\n",
        "# for path in paths:\r\n",
        "#     for c in range(12):\r\n",
        "#         pieces_to_consider = [opus for opus in full_dict_dataset \r\n",
        "#                               if (opus[\"original_path\"] == path and opus[\"transposed_of\"] in interval_dict[c])  ]\r\n",
        "#         # print(\"Path\", path, \". Chromatic: \",c)\r\n",
        "#         # print(len(pieces_to_consider))\r\n",
        "#         n_accidentals = [sum([pitch.count(\"#\") + pitch.count(\"-\") for pitch in opus[\"pitches\"]]) \r\n",
        "#                          for opus in pieces_to_consider]\r\n",
        "#         # print(n_accidentals)\r\n",
        "#         # print(pieces_to_consider[np.argmin(n_accidentals)][\"pitches\"][0:20])\r\n",
        "#         if len(pieces_to_consider)>0:\r\n",
        "#             dict_dataset.append(pieces_to_consider[np.argmin(n_accidentals)])\r\n",
        "#         else:\r\n",
        "#             print(\"No options for\", path, \". Chromatic: \",c )\r\n",
        "\r\n",
        "accepted_ks = range(-5,6)\r\n",
        "dict_dataset = [e for e in full_dict_dataset if e[\"key_signature\"] in accepted_ks]\r\n",
        "\r\n",
        "#test if it worked\r\n",
        "for i,e in enumerate(dict_dataset):\r\n",
        "    print(e[\"original_path\"], e[\"transposed_of\"], e[\"key_signature\"])\r\n",
        "    print(e[\"pitches\"][:10])\r\n",
        "    print(e[\"midi_number\"][:10])\r\n",
        "    if i == 100:\r\n",
        "        break"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bach/Fugue/bwv_846/xml_score.musicxml P1 0\n",
            "['C', 'D', 'E', 'F', 'G', 'F', 'E', 'A', 'D', 'G']\n",
            "[0, 2, 4, 5, 7, 5, 4, 9, 2, 7]\n",
            "Bach/Fugue/bwv_846/xml_score.musicxml m2 -5\n",
            "['D-', 'E-', 'F', 'G-', 'A-', 'G-', 'F', 'B-', 'E-', 'A-']\n",
            "[1, 3, 5, 6, 8, 6, 5, 10, 3, 8]\n",
            "Bach/Fugue/bwv_846/xml_score.musicxml M2 2\n",
            "['D', 'E', 'F#', 'G', 'A', 'G', 'F#', 'B', 'E', 'A']\n",
            "[2, 4, 6, 7, 9, 7, 6, 11, 4, 9]\n",
            "Bach/Fugue/bwv_846/xml_score.musicxml m3 -3\n",
            "['E-', 'F', 'G', 'A-', 'B-', 'A-', 'G', 'C', 'F', 'B-']\n",
            "[3, 5, 7, 8, 10, 8, 7, 0, 5, 10]\n",
            "Bach/Fugue/bwv_846/xml_score.musicxml M3 4\n",
            "['E', 'F#', 'G#', 'A', 'B', 'A', 'G#', 'C#', 'F#', 'B']\n",
            "[4, 6, 8, 9, 11, 9, 8, 1, 6, 11]\n",
            "Bach/Fugue/bwv_846/xml_score.musicxml P4 -1\n",
            "['F', 'G', 'A', 'B-', 'C', 'B-', 'A', 'D', 'G', 'C']\n",
            "[5, 7, 9, 10, 0, 10, 9, 2, 7, 0]\n",
            "Bach/Fugue/bwv_846/xml_score.musicxml P5 1\n",
            "['G', 'A', 'B', 'C', 'D', 'C', 'B', 'E', 'A', 'D']\n",
            "[7, 9, 11, 0, 2, 0, 11, 4, 9, 2]\n",
            "Bach/Fugue/bwv_846/xml_score.musicxml m6 -4\n",
            "['A-', 'B-', 'C', 'D-', 'E-', 'D-', 'C', 'F', 'B-', 'E-']\n",
            "[8, 10, 0, 1, 3, 1, 0, 5, 10, 3]\n",
            "Bach/Fugue/bwv_846/xml_score.musicxml M6 3\n",
            "['A', 'B', 'C#', 'D', 'E', 'D', 'C#', 'F#', 'B', 'E']\n",
            "[9, 11, 1, 2, 4, 2, 1, 6, 11, 4]\n",
            "Bach/Fugue/bwv_846/xml_score.musicxml m7 -2\n",
            "['B-', 'C', 'D', 'E-', 'F', 'E-', 'D', 'G', 'C', 'F']\n",
            "[10, 0, 2, 3, 5, 3, 2, 7, 0, 5]\n",
            "Bach/Fugue/bwv_846/xml_score.musicxml M7 5\n",
            "['B', 'C#', 'D#', 'E', 'F#', 'E', 'D#', 'G#', 'C#', 'F#']\n",
            "[11, 1, 3, 4, 6, 4, 3, 8, 1, 6]\n",
            "Bach/Fugue/bwv_848/xml_score.musicxml d2 -5\n",
            "['A-', 'B-', 'A-', 'G-', 'A-', 'F', 'D-', 'A-', 'G-', 'F']\n",
            "[8, 10, 8, 6, 8, 5, 1, 8, 6, 5]\n",
            "Bach/Fugue/bwv_848/xml_score.musicxml m2 2\n",
            "['A', 'B', 'A', 'G', 'A', 'F#', 'D', 'A', 'G', 'F#']\n",
            "[9, 11, 9, 7, 9, 6, 2, 9, 7, 6]\n",
            "Bach/Fugue/bwv_848/xml_score.musicxml d3 -3\n",
            "['B-', 'C', 'B-', 'A-', 'B-', 'G', 'E-', 'B-', 'A-', 'G']\n",
            "[10, 0, 10, 8, 10, 7, 3, 10, 8, 7]\n",
            "Bach/Fugue/bwv_848/xml_score.musicxml m3 4\n",
            "['B', 'C#', 'B', 'A', 'B', 'G#', 'E', 'B', 'A', 'G#']\n",
            "[11, 1, 11, 9, 11, 8, 4, 11, 9, 8]\n",
            "Bach/Fugue/bwv_848/xml_score.musicxml d4 -1\n",
            "['C', 'D', 'C', 'B-', 'C', 'A', 'F', 'C', 'B-', 'A']\n",
            "[0, 2, 0, 10, 0, 9, 5, 0, 10, 9]\n",
            "Bach/Fugue/bwv_848/xml_score.musicxml d5 1\n",
            "['D', 'E', 'D', 'C', 'D', 'B', 'G', 'D', 'C', 'B']\n",
            "[2, 4, 2, 0, 2, 11, 7, 2, 0, 11]\n",
            "Bach/Fugue/bwv_848/xml_score.musicxml d6 -4\n",
            "['E-', 'F', 'E-', 'D-', 'E-', 'C', 'A-', 'E-', 'D-', 'C']\n",
            "[3, 5, 3, 1, 3, 0, 8, 3, 1, 0]\n",
            "Bach/Fugue/bwv_848/xml_score.musicxml m6 3\n",
            "['E', 'F#', 'E', 'D', 'E', 'C#', 'A', 'E', 'D', 'C#']\n",
            "[4, 6, 4, 2, 4, 1, 9, 4, 2, 1]\n",
            "Bach/Fugue/bwv_848/xml_score.musicxml d7 -2\n",
            "['F', 'G', 'F', 'E-', 'F', 'D', 'B-', 'F', 'E-', 'D']\n",
            "[5, 7, 5, 3, 5, 2, 10, 5, 3, 2]\n",
            "Bach/Fugue/bwv_848/xml_score.musicxml m7 5\n",
            "['F#', 'G#', 'F#', 'E', 'F#', 'D#', 'B', 'F#', 'E', 'D#']\n",
            "[6, 8, 6, 4, 6, 3, 11, 6, 4, 3]\n",
            "Bach/Fugue/bwv_848/xml_score.musicxml d1 0\n",
            "['G', 'A', 'G', 'F', 'G', 'E', 'C', 'G', 'F', 'E']\n",
            "[7, 9, 7, 5, 7, 4, 0, 7, 5, 4]\n",
            "Bach/Fugue/bwv_854/xml_score.musicxml P1 4\n",
            "['E', 'F#', 'B', 'C#', 'D#', 'E', 'D#', 'E', 'F#', 'G#']\n",
            "[4, 6, 11, 1, 3, 4, 3, 4, 6, 8]\n",
            "Bach/Fugue/bwv_854/xml_score.musicxml m2 -1\n",
            "['F', 'G', 'C', 'D', 'E', 'F', 'E', 'F', 'G', 'A']\n",
            "[5, 7, 0, 2, 4, 5, 4, 5, 7, 9]\n",
            "Bach/Fugue/bwv_854/xml_score.musicxml m3 1\n",
            "['G', 'A', 'D', 'E', 'F#', 'G', 'F#', 'G', 'A', 'B']\n",
            "[7, 9, 2, 4, 6, 7, 6, 7, 9, 11]\n",
            "Bach/Fugue/bwv_854/xml_score.musicxml d4 -4\n",
            "['A-', 'B-', 'E-', 'F', 'G', 'A-', 'G', 'A-', 'B-', 'C']\n",
            "[8, 10, 3, 5, 7, 8, 7, 8, 10, 0]\n",
            "Bach/Fugue/bwv_854/xml_score.musicxml P4 3\n",
            "['A', 'B', 'E', 'F#', 'G#', 'A', 'G#', 'A', 'B', 'C#']\n",
            "[9, 11, 4, 6, 8, 9, 8, 9, 11, 1]\n",
            "Bach/Fugue/bwv_854/xml_score.musicxml d5 -2\n",
            "['B-', 'C', 'F', 'G', 'A', 'B-', 'A', 'B-', 'C', 'D']\n",
            "[10, 0, 5, 7, 9, 10, 9, 10, 0, 2]\n",
            "Bach/Fugue/bwv_854/xml_score.musicxml P5 5\n",
            "['B', 'C#', 'F#', 'G#', 'A#', 'B', 'A#', 'B', 'C#', 'D#']\n",
            "[11, 1, 6, 8, 10, 11, 10, 11, 1, 3]\n",
            "Bach/Fugue/bwv_854/xml_score.musicxml m6 0\n",
            "['C', 'D', 'G', 'A', 'B', 'C', 'B', 'C', 'D', 'E']\n",
            "[0, 2, 7, 9, 11, 0, 11, 0, 2, 4]\n",
            "Bach/Fugue/bwv_854/xml_score.musicxml d7 -5\n",
            "['D-', 'E-', 'A-', 'B-', 'C', 'D-', 'C', 'D-', 'E-', 'F']\n",
            "[1, 3, 8, 10, 0, 1, 0, 1, 3, 5]\n",
            "Bach/Fugue/bwv_854/xml_score.musicxml m7 2\n",
            "['D', 'E', 'A', 'B', 'C#', 'D', 'C#', 'D', 'E', 'F#']\n",
            "[2, 4, 9, 11, 1, 2, 1, 2, 4, 6]\n",
            "Bach/Fugue/bwv_854/xml_score.musicxml d1 -3\n",
            "['E-', 'F', 'B-', 'C', 'D', 'E-', 'D', 'E-', 'F', 'G']\n",
            "[3, 5, 10, 0, 2, 3, 2, 3, 5, 7]\n",
            "Bach/Fugue/bwv_856/xml_score.musicxml P1 -1\n",
            "['C', 'D', 'C', 'B-', 'C', 'E', 'F', 'G', 'A', 'B-']\n",
            "[0, 2, 0, 10, 0, 4, 5, 7, 9, 10]\n",
            "Bach/Fugue/bwv_856/xml_score.musicxml M2 1\n",
            "['D', 'E', 'D', 'C', 'D', 'F#', 'G', 'A', 'B', 'C']\n",
            "[2, 4, 2, 0, 2, 6, 7, 9, 11, 0]\n",
            "Bach/Fugue/bwv_856/xml_score.musicxml m3 -4\n",
            "['E-', 'F', 'E-', 'D-', 'E-', 'G', 'A-', 'B-', 'C', 'D-']\n",
            "[3, 5, 3, 1, 3, 7, 8, 10, 0, 1]\n",
            "Bach/Fugue/bwv_856/xml_score.musicxml M3 3\n",
            "['E', 'F#', 'E', 'D', 'E', 'G#', 'A', 'B', 'C#', 'D']\n",
            "[4, 6, 4, 2, 4, 8, 9, 11, 1, 2]\n",
            "Bach/Fugue/bwv_856/xml_score.musicxml P4 -2\n",
            "['F', 'G', 'F', 'E-', 'F', 'A', 'B-', 'C', 'D', 'E-']\n",
            "[5, 7, 5, 3, 5, 9, 10, 0, 2, 3]\n",
            "Bach/Fugue/bwv_856/xml_score.musicxml A4 5\n",
            "['F#', 'G#', 'F#', 'E', 'F#', 'A#', 'B', 'C#', 'D#', 'E']\n",
            "[6, 8, 6, 4, 6, 10, 11, 1, 3, 4]\n",
            "Bach/Fugue/bwv_856/xml_score.musicxml P5 0\n",
            "['G', 'A', 'G', 'F', 'G', 'B', 'C', 'D', 'E', 'F']\n",
            "[7, 9, 7, 5, 7, 11, 0, 2, 4, 5]\n",
            "Bach/Fugue/bwv_856/xml_score.musicxml m6 -5\n",
            "['A-', 'B-', 'A-', 'G-', 'A-', 'C', 'D-', 'E-', 'F', 'G-']\n",
            "[8, 10, 8, 6, 8, 0, 1, 3, 5, 6]\n",
            "Bach/Fugue/bwv_856/xml_score.musicxml M6 2\n",
            "['A', 'B', 'A', 'G', 'A', 'C#', 'D', 'E', 'F#', 'G']\n",
            "[9, 11, 9, 7, 9, 1, 2, 4, 6, 7]\n",
            "Bach/Fugue/bwv_856/xml_score.musicxml m7 -3\n",
            "['B-', 'C', 'B-', 'A-', 'B-', 'D', 'E-', 'F', 'G', 'A-']\n",
            "[10, 0, 10, 8, 10, 2, 3, 5, 7, 8]\n",
            "Bach/Fugue/bwv_856/xml_score.musicxml M7 4\n",
            "['B', 'C#', 'B', 'A', 'B', 'D#', 'E', 'F#', 'G#', 'A']\n",
            "[11, 1, 11, 9, 11, 3, 4, 6, 8, 9]\n",
            "Bach/Fugue/bwv_857/xml_score.musicxml P1 -4\n",
            "['C', 'D-', 'C', 'B', 'E', 'F', 'B-', 'A', 'A-', 'G']\n",
            "[0, 1, 0, 11, 4, 5, 10, 9, 8, 7]\n",
            "Bach/Fugue/bwv_857/xml_score.musicxml A1 3\n",
            "['C#', 'D', 'C#', 'B#', 'E#', 'F#', 'B', 'A#', 'A', 'G#']\n",
            "[1, 2, 1, 0, 5, 6, 11, 10, 9, 8]\n",
            "Bach/Fugue/bwv_857/xml_score.musicxml M2 -2\n",
            "['D', 'E-', 'D', 'C#', 'F#', 'G', 'C', 'B', 'B-', 'A']\n",
            "[2, 3, 2, 1, 6, 7, 0, 11, 10, 9]\n",
            "Bach/Fugue/bwv_857/xml_score.musicxml A2 5\n",
            "['D#', 'E', 'D#', 'C##', 'F##', 'G#', 'C#', 'B#', 'B', 'A#']\n",
            "[3, 4, 3, 2, 7, 8, 1, 0, 11, 10]\n",
            "Bach/Fugue/bwv_857/xml_score.musicxml M3 0\n",
            "['E', 'F', 'E', 'D#', 'G#', 'A', 'D', 'C#', 'C', 'B']\n",
            "[4, 5, 4, 3, 8, 9, 2, 1, 0, 11]\n",
            "Bach/Fugue/bwv_857/xml_score.musicxml P4 -5\n",
            "['F', 'G-', 'F', 'E', 'A', 'B-', 'E-', 'D', 'D-', 'C']\n",
            "[5, 6, 5, 4, 9, 10, 3, 2, 1, 0]\n",
            "Bach/Fugue/bwv_857/xml_score.musicxml A4 2\n",
            "['F#', 'G', 'F#', 'E#', 'A#', 'B', 'E', 'D#', 'D', 'C#']\n",
            "[6, 7, 6, 5, 10, 11, 4, 3, 2, 1]\n",
            "Bach/Fugue/bwv_857/xml_score.musicxml P5 -3\n",
            "['G', 'A-', 'G', 'F#', 'B', 'C', 'F', 'E', 'E-', 'D']\n",
            "[7, 8, 7, 6, 11, 0, 5, 4, 3, 2]\n",
            "Bach/Fugue/bwv_857/xml_score.musicxml A5 4\n",
            "['G#', 'A', 'G#', 'F##', 'B#', 'C#', 'F#', 'E#', 'E', 'D#']\n",
            "[8, 9, 8, 7, 0, 1, 6, 5, 4, 3]\n",
            "Bach/Fugue/bwv_857/xml_score.musicxml M6 -1\n",
            "['A', 'B-', 'A', 'G#', 'C#', 'D', 'G', 'F#', 'F', 'E']\n",
            "[9, 10, 9, 8, 1, 2, 7, 6, 5, 4]\n",
            "Bach/Fugue/bwv_857/xml_score.musicxml M7 1\n",
            "['B', 'C', 'B', 'A#', 'D#', 'E', 'A', 'G#', 'G', 'F#']\n",
            "[11, 0, 11, 10, 3, 4, 9, 8, 7, 6]\n",
            "Bach/Fugue/bwv_858/xml_score.musicxml m2 1\n",
            "['D', 'G', 'F#', 'G', 'F#', 'E', 'E', 'D', 'D', 'E']\n",
            "[2, 7, 6, 7, 6, 4, 4, 2, 2, 4]\n",
            "Bach/Fugue/bwv_858/xml_score.musicxml d3 -4\n",
            "['E-', 'A-', 'G', 'A-', 'G', 'F', 'F', 'E-', 'E-', 'F']\n",
            "[3, 8, 7, 8, 7, 5, 5, 3, 3, 5]\n",
            "Bach/Fugue/bwv_858/xml_score.musicxml m3 3\n",
            "['E', 'A', 'G#', 'A', 'G#', 'F#', 'F#', 'E', 'E', 'F#']\n",
            "[4, 9, 8, 9, 8, 6, 6, 4, 4, 6]\n",
            "Bach/Fugue/bwv_858/xml_score.musicxml d4 -2\n",
            "['F', 'B-', 'A', 'B-', 'A', 'G', 'G', 'F', 'F', 'G']\n",
            "[5, 10, 9, 10, 9, 7, 7, 5, 5, 7]\n",
            "Bach/Fugue/bwv_858/xml_score.musicxml P4 5\n",
            "['F#', 'B', 'A#', 'B', 'A#', 'G#', 'G#', 'F#', 'F#', 'G#']\n",
            "[6, 11, 10, 11, 10, 8, 8, 6, 6, 8]\n",
            "Bach/Fugue/bwv_858/xml_score.musicxml d5 0\n",
            "['G', 'C', 'B', 'C', 'B', 'A', 'A', 'G', 'G', 'A']\n",
            "[7, 0, 11, 0, 11, 9, 9, 7, 7, 9]\n",
            "Bach/Fugue/bwv_858/xml_score.musicxml d6 -5\n",
            "['A-', 'D-', 'C', 'D-', 'C', 'B-', 'B-', 'A-', 'A-', 'B-']\n",
            "[8, 1, 0, 1, 0, 10, 10, 8, 8, 10]\n",
            "Bach/Fugue/bwv_858/xml_score.musicxml m6 2\n",
            "['A', 'D', 'C#', 'D', 'C#', 'B', 'B', 'A', 'A', 'B']\n",
            "[9, 2, 1, 2, 1, 11, 11, 9, 9, 11]\n",
            "Bach/Fugue/bwv_858/xml_score.musicxml d7 -3\n",
            "['B-', 'E-', 'D', 'E-', 'D', 'C', 'C', 'B-', 'B-', 'C']\n",
            "[10, 3, 2, 3, 2, 0, 0, 10, 10, 0]\n",
            "Bach/Fugue/bwv_858/xml_score.musicxml m7 4\n",
            "['B', 'E', 'D#', 'E', 'D#', 'C#', 'C#', 'B', 'B', 'C#']\n",
            "[11, 4, 3, 4, 3, 1, 1, 11, 11, 1]\n",
            "Bach/Fugue/bwv_858/xml_score.musicxml d1 -1\n",
            "['C', 'F', 'E', 'F', 'E', 'D', 'D', 'C', 'C', 'D']\n",
            "[0, 5, 4, 5, 4, 2, 2, 0, 0, 2]\n",
            "Bach/Fugue/bwv_860/xml_score.musicxml P1 1\n",
            "['G', 'A', 'G', 'F#', 'G', 'A', 'B', 'A', 'G', 'A']\n",
            "[7, 9, 7, 6, 7, 9, 11, 9, 7, 9]\n",
            "Bach/Fugue/bwv_860/xml_score.musicxml m2 -4\n",
            "['A-', 'B-', 'A-', 'G', 'A-', 'B-', 'C', 'B-', 'A-', 'B-']\n",
            "[8, 10, 8, 7, 8, 10, 0, 10, 8, 10]\n",
            "Bach/Fugue/bwv_860/xml_score.musicxml M2 3\n",
            "['A', 'B', 'A', 'G#', 'A', 'B', 'C#', 'B', 'A', 'B']\n",
            "[9, 11, 9, 8, 9, 11, 1, 11, 9, 11]\n",
            "Bach/Fugue/bwv_860/xml_score.musicxml m3 -2\n",
            "['B-', 'C', 'B-', 'A', 'B-', 'C', 'D', 'C', 'B-', 'C']\n",
            "[10, 0, 10, 9, 10, 0, 2, 0, 10, 0]\n",
            "Bach/Fugue/bwv_860/xml_score.musicxml M3 5\n",
            "['B', 'C#', 'B', 'A#', 'B', 'C#', 'D#', 'C#', 'B', 'C#']\n",
            "[11, 1, 11, 10, 11, 1, 3, 1, 11, 1]\n",
            "Bach/Fugue/bwv_860/xml_score.musicxml P4 0\n",
            "['C', 'D', 'C', 'B', 'C', 'D', 'E', 'D', 'C', 'D']\n",
            "[0, 2, 0, 11, 0, 2, 4, 2, 0, 2]\n",
            "Bach/Fugue/bwv_860/xml_score.musicxml d5 -5\n",
            "['D-', 'E-', 'D-', 'C', 'D-', 'E-', 'F', 'E-', 'D-', 'E-']\n",
            "[1, 3, 1, 0, 1, 3, 5, 3, 1, 3]\n",
            "Bach/Fugue/bwv_860/xml_score.musicxml P5 2\n",
            "['D', 'E', 'D', 'C#', 'D', 'E', 'F#', 'E', 'D', 'E']\n",
            "[2, 4, 2, 1, 2, 4, 6, 4, 2, 4]\n",
            "Bach/Fugue/bwv_860/xml_score.musicxml m6 -3\n",
            "['E-', 'F', 'E-', 'D', 'E-', 'F', 'G', 'F', 'E-', 'F']\n",
            "[3, 5, 3, 2, 3, 5, 7, 5, 3, 5]\n",
            "Bach/Fugue/bwv_860/xml_score.musicxml M6 4\n",
            "['E', 'F#', 'E', 'D#', 'E', 'F#', 'G#', 'F#', 'E', 'F#']\n",
            "[4, 6, 4, 3, 4, 6, 8, 6, 4, 6]\n",
            "Bach/Fugue/bwv_860/xml_score.musicxml m7 -1\n",
            "['F', 'G', 'F', 'E', 'F', 'G', 'A', 'G', 'F', 'G']\n",
            "[5, 7, 5, 4, 5, 7, 9, 7, 5, 7]\n",
            "Bach/Fugue/bwv_862/xml_score.musicxml P1 -4\n",
            "['A-', 'E-', 'C', 'A-', 'F', 'D-', 'E-', 'E-', 'E-', 'D-']\n",
            "[8, 3, 0, 8, 5, 1, 3, 3, 3, 1]\n",
            "Bach/Fugue/bwv_862/xml_score.musicxml A1 3\n",
            "['A', 'E', 'C#', 'A', 'F#', 'D', 'E', 'E', 'E', 'D']\n",
            "[9, 4, 1, 9, 6, 2, 4, 4, 4, 2]\n",
            "Bach/Fugue/bwv_862/xml_score.musicxml M2 -2\n",
            "['B-', 'F', 'D', 'B-', 'G', 'E-', 'F', 'F', 'F', 'E-']\n",
            "[10, 5, 2, 10, 7, 3, 5, 5, 5, 3]\n",
            "Bach/Fugue/bwv_862/xml_score.musicxml A2 5\n",
            "['B', 'F#', 'D#', 'B', 'G#', 'E', 'F#', 'F#', 'F#', 'E']\n",
            "[11, 6, 3, 11, 8, 4, 6, 6, 6, 4]\n",
            "Bach/Fugue/bwv_862/xml_score.musicxml M3 0\n",
            "['C', 'G', 'E', 'C', 'A', 'F', 'G', 'G', 'G', 'F']\n",
            "[0, 7, 4, 0, 9, 5, 7, 7, 7, 5]\n",
            "Bach/Fugue/bwv_862/xml_score.musicxml P4 -5\n",
            "['D-', 'A-', 'F', 'D-', 'B-', 'G-', 'A-', 'A-', 'A-', 'G-']\n",
            "[1, 8, 5, 1, 10, 6, 8, 8, 8, 6]\n",
            "Bach/Fugue/bwv_862/xml_score.musicxml A4 2\n",
            "['D', 'A', 'F#', 'D', 'B', 'G', 'A', 'A', 'A', 'G']\n",
            "[2, 9, 6, 2, 11, 7, 9, 9, 9, 7]\n",
            "Bach/Fugue/bwv_862/xml_score.musicxml P5 -3\n",
            "['E-', 'B-', 'G', 'E-', 'C', 'A-', 'B-', 'B-', 'B-', 'A-']\n",
            "[3, 10, 7, 3, 0, 8, 10, 10, 10, 8]\n",
            "Bach/Fugue/bwv_862/xml_score.musicxml A5 4\n",
            "['E', 'B', 'G#', 'E', 'C#', 'A', 'B', 'B', 'B', 'A']\n",
            "[4, 11, 8, 4, 1, 9, 11, 11, 11, 9]\n",
            "Bach/Fugue/bwv_862/xml_score.musicxml M6 -1\n",
            "['F', 'C', 'A', 'F', 'D', 'B-', 'C', 'C', 'C', 'B-']\n",
            "[5, 0, 9, 5, 2, 10, 0, 0, 0, 10]\n",
            "Bach/Fugue/bwv_862/xml_score.musicxml M7 1\n",
            "['G', 'D', 'B', 'G', 'E', 'C', 'D', 'D', 'D', 'C']\n",
            "[7, 2, 11, 7, 4, 0, 2, 2, 2, 0]\n",
            "Bach/Fugue/bwv_863/xml_score.musicxml P1 5\n",
            "['G#', 'F##', 'G#', 'A#', 'B', 'A#', 'G#', 'C##', 'D#', 'F#']\n",
            "[8, 7, 8, 10, 11, 10, 8, 2, 3, 6]\n",
            "Bach/Fugue/bwv_863/xml_score.musicxml m2 0\n",
            "['A', 'G#', 'A', 'B', 'C', 'B', 'A', 'D#', 'E', 'G']\n",
            "[9, 8, 9, 11, 0, 11, 9, 3, 4, 7]\n",
            "Bach/Fugue/bwv_863/xml_score.musicxml d3 -5\n",
            "['B-', 'A', 'B-', 'C', 'D-', 'C', 'B-', 'E', 'F', 'A-']\n",
            "[10, 9, 10, 0, 1, 0, 10, 4, 5, 8]\n",
            "Bach/Fugue/bwv_863/xml_score.musicxml m3 2\n",
            "['B', 'A#', 'B', 'C#', 'D', 'C#', 'B', 'E#', 'F#', 'A']\n",
            "[11, 10, 11, 1, 2, 1, 11, 5, 6, 9]\n",
            "Bach/Fugue/bwv_863/xml_score.musicxml d4 -3\n",
            "['C', 'B', 'C', 'D', 'E-', 'D', 'C', 'F#', 'G', 'B-']\n",
            "[0, 11, 0, 2, 3, 2, 0, 6, 7, 10]\n",
            "Bach/Fugue/bwv_863/xml_score.musicxml P4 4\n",
            "['C#', 'B#', 'C#', 'D#', 'E', 'D#', 'C#', 'F##', 'G#', 'B']\n",
            "[1, 0, 1, 3, 4, 3, 1, 7, 8, 11]\n",
            "Bach/Fugue/bwv_863/xml_score.musicxml d5 -1\n",
            "['D', 'C#', 'D', 'E', 'F', 'E', 'D', 'G#', 'A', 'C']\n",
            "[2, 1, 2, 4, 5, 4, 2, 8, 9, 0]\n",
            "Bach/Fugue/bwv_863/xml_score.musicxml m6 1\n",
            "['E', 'D#', 'E', 'F#', 'G', 'F#', 'E', 'A#', 'B', 'D']\n",
            "[4, 3, 4, 6, 7, 6, 4, 10, 11, 2]\n",
            "Bach/Fugue/bwv_863/xml_score.musicxml d7 -4\n",
            "['F', 'E', 'F', 'G', 'A-', 'G', 'F', 'B', 'C', 'E-']\n",
            "[5, 4, 5, 7, 8, 7, 5, 11, 0, 3]\n",
            "Bach/Fugue/bwv_863/xml_score.musicxml m7 3\n",
            "['F#', 'E#', 'F#', 'G#', 'A', 'G#', 'F#', 'B#', 'C#', 'E']\n",
            "[6, 5, 6, 8, 9, 8, 6, 0, 1, 4]\n",
            "Bach/Fugue/bwv_863/xml_score.musicxml d1 -2\n",
            "['G', 'F#', 'G', 'A', 'B-', 'A', 'G', 'C#', 'D', 'F']\n",
            "[7, 6, 7, 9, 10, 9, 7, 1, 2, 5]\n",
            "Bach/Fugue/bwv_864/xml_score.musicxml P1 3\n",
            "['A', 'G#', 'C#', 'A', 'D', 'B', 'E', 'E', 'C#', 'F#']\n",
            "[9, 8, 1, 9, 2, 11, 4, 4, 1, 6]\n",
            "Bach/Fugue/bwv_864/xml_score.musicxml m2 -2\n",
            "['B-', 'A', 'D', 'B-', 'E-', 'C', 'F', 'F', 'D', 'G']\n",
            "[10, 9, 2, 10, 3, 0, 5, 5, 2, 7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgHkMeoJdb42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33014837-6921-47fe-bf2a-ea2db5496e6c"
      },
      "source": [
        "c = Counter()\r\n",
        "for p in paths:\r\n",
        "    c[p.split(\"/\")[0]] +=1\r\n",
        "\r\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'Bach': 59, 'Beethoven': 57, 'Haydn': 11, 'Mozart': 6})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GRCM2W3qqeW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09fb8742-4304-4803-bc6d-e04cf65737e3"
      },
      "source": [
        "# Ignore Brahms (only one piece)\r\n",
        "paths = [p for p in paths if p.split(\"/\")[0] !=\"Brahms\"]\r\n",
        "\r\n",
        "# Divide train and validation set\r\n",
        "path_train, path_validation = sklearn.model_selection.train_test_split(paths, test_size=0.2,stratify=[p.split(\"/\")[0] for p in paths ])\r\n",
        "print(\"Train and validation lenghts: \",len(path_train),len(path_validation))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train and validation lenghts:  106 27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "KIZ2_bX1bom5",
        "outputId": "4268b99a-1adc-4178-d567-eca532b0e443"
      },
      "source": [
        "#need to find a better way to visualize this\r\n",
        "composers = list(set([p.split(\"/\")[0] for p in paths ]))\r\n",
        "print(composers)\r\n",
        "\r\n",
        "train_composer = [composers.index(p.split(\"/\")[0]) for p in path_train]\r\n",
        "val_composer = [composers.index(p.split(\"/\")[0]) for p in path_validation]\r\n",
        "\r\n",
        "_ = plt.hist([train_composer, val_composer], label=['train', 'validation'])\r\n",
        "_ = plt.legend(loc='upper left')\r\n",
        "_ = plt.xticks(list(range(7)), composers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Mozart', 'Bach', 'Haydn', 'Beethoven']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 369,
              "height": 248
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-qaT10ApkCY"
      },
      "source": [
        "## Transform the input into a convenient format for the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEYec2TDOWvj",
        "outputId": "58e77be7-2dfc-4bd0-a4ea-c1b46e310836"
      },
      "source": [
        "# Helper functions to feed the correct input into the NN \r\n",
        "\r\n",
        "PAD = \"<PAD>\"\r\n",
        "\r\n",
        "tag_to_ix = {p: accepted_pitches.index(p) for p in accepted_pitches}\r\n",
        "#add PADDING TAD\r\n",
        "tag_to_ix[PAD] = len(accepted_pitches)\r\n",
        "\r\n",
        "midi_to_ix = {m: m for m in range(12)}\r\n",
        "# #add PADDING TAD\r\n",
        "# midi_to_ix[PAD] = 12\r\n",
        "\r\n",
        "print(midi_to_ix[1])\r\n",
        "print(len(midi_to_ix))\r\n",
        "\r\n",
        "\r\n",
        "class Pitch2Diatonic():\r\n",
        "  def __call__(self, in_seq):\r\n",
        "    return [p for p in in_seq]\r\n",
        "\r\n",
        "class Diatonic2Int():\r\n",
        "  def __call__(self, in_seq):\r\n",
        "    idxs = [tag_to_ix[w] for w in in_seq]\r\n",
        "    return idxs\r\n",
        "\r\n",
        "class Int2Pitch():\r\n",
        "  def __call__(self, in_seq):\r\n",
        "    return [accepted_pitches[i] for i in in_seq]\r\n",
        "\r\n",
        "class OneHotEncoder():\r\n",
        "    def __init__(self, alphabet_len):\r\n",
        "        self.alphabet_len = alphabet_len\r\n",
        "        \r\n",
        "    def __call__(self, sample):\r\n",
        "        onehot = np.zeros([len(sample), self.alphabet_len])\r\n",
        "        tot_chars = len(sample)\r\n",
        "        onehot[np.arange(tot_chars), sample] = 1\r\n",
        "        return onehot\r\n",
        "        \r\n",
        "class ToTensorFloat():\r\n",
        "  def __call__(self, sample):\r\n",
        "    return torch.tensor(sample,dtype=torch.float)\r\n",
        "\r\n",
        "class ToTensorLong():\r\n",
        "  def __call__(self, sample):\r\n",
        "    return torch.tensor(sample,dtype=torch.long)\r\n",
        "\r\n",
        "\r\n",
        "pitches_len = len(accepted_pitches)\r\n",
        "midinote_len = 12\r\n",
        "\r\n",
        "### Define the preprocessing pipeline\r\n",
        "transform_diat = transforms.Compose([\r\n",
        "                                     Pitch2Diatonic(),\r\n",
        "                                     Diatonic2Int(),\r\n",
        "                                     ToTensorLong()])\r\n",
        "transform_chrom = transforms.Compose([\r\n",
        "                                      OneHotEncoder(len(midi_to_ix)),\r\n",
        "                                      ToTensorFloat()])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV9boYaToUs2",
        "outputId": "ae8ad502-0842-4a6a-f021-34b92760363d"
      },
      "source": [
        "# Create the dataset\r\n",
        "\r\n",
        "class PSDataset(Dataset):\r\n",
        "    def __init__(self, dict_dataset, paths, transf_c, transf_d, augment_dataset, truncate = None):\r\n",
        "        if augment_dataset:\r\n",
        "            self.chromatic_sequences = [e[\"midi_number\"] for e in dict_dataset if e[\"original_path\"] in paths]\r\n",
        "            self.diatonic_sequences = [e[\"pitches\"]\r\n",
        "                                       for e in dict_dataset \r\n",
        "                                       if e[\"original_path\"] in paths]\r\n",
        "        else: #consider only non transposed pieces\r\n",
        "            self.chromatic_sequences = [e[\"midi_number\"] for e in dict_dataset \r\n",
        "                                        if (e[\"original_path\"] in paths and e[\"transposed_of\"]==\"P1\")]\r\n",
        "            self.diatonic_sequences = [e[\"pitches\"]\r\n",
        "                                       for e in dict_dataset \r\n",
        "                                       if (e[\"original_path\"] in paths and e[\"transposed_of\"]==\"P1\")]\r\n",
        "        #the transformations to apply to data\r\n",
        "        self.transf_c = transf_c\r\n",
        "        self.transf_d = transf_d\r\n",
        "        self.truncate = truncate\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.chromatic_sequences)\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        chromatic_seq = self.chromatic_sequences[idx]\r\n",
        "        diatonic_seq = self.diatonic_sequences[idx]\r\n",
        "        \r\n",
        "\r\n",
        "        #transform\r\n",
        "        chromatic_seq = self.transf_c(chromatic_seq)\r\n",
        "        diatonic_seq = self.transf_d(diatonic_seq)\r\n",
        "\r\n",
        "        if not self.truncate is None:\r\n",
        "            if len(diatonic_seq) > self.truncate:\r\n",
        "                chromatic_seq = chromatic_seq[0:self.truncate]\r\n",
        "                diatonic_seq = diatonic_seq[0:self.truncate]\r\n",
        "\r\n",
        "        #sanity check\r\n",
        "        assert len(chromatic_seq) == len(diatonic_seq)\r\n",
        "        seq_len = len(diatonic_seq)\r\n",
        "        \r\n",
        "        return chromatic_seq, diatonic_seq, seq_len\r\n",
        "\r\n",
        "train_dataset = PSDataset(dict_dataset,path_train, transform_chrom,transform_diat,True)\r\n",
        "validation_dataset = PSDataset(dict_dataset,path_validation, transform_chrom,transform_diat, False)\r\n",
        "\r\n",
        "print(len(train_dataset),len(validation_dataset))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# test if it works\r\n",
        "chrom, diat, l = next(iter(train_dataset))\r\n",
        "print([[i for i, j in enumerate(m) if j == 1][0] for m in chrom[0:30]])\r\n",
        "# print([diatonic_pitches[p.item()] for p in diat[0:30]])\r\n",
        "print([accepted_pitches[p.item()] for p in diat[0:30]])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1159 26\n",
            "[0, 2, 4, 5, 7, 5, 4, 9, 2, 7, 7, 9, 7, 5, 4, 5, 7, 4, 2, 9, 0, 2, 11, 0, 11, 0, 9, 6, 2, 0]\n",
            "['C', 'D', 'E', 'F', 'G', 'F', 'E', 'A', 'D', 'G', 'G', 'A', 'G', 'F', 'E', 'F', 'G', 'E', 'D', 'A', 'C', 'D', 'B', 'C', 'B', 'C', 'A', 'F#', 'D', 'C']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAubyjw2LC8P",
        "outputId": "c6fbedb6-2f8f-4c5d-e2c8-c07a8353fa41"
      },
      "source": [
        "def pad_collate(batch):\r\n",
        "    (xx, yy, l) = zip(*batch)\r\n",
        "    \r\n",
        "    xx_pad = pad_sequence(xx)\r\n",
        "    yy_pad = pad_sequence(yy, padding_value=tag_to_ix[PAD])\r\n",
        "\r\n",
        "    #sort the sequences by length\r\n",
        "    seq_lengths, perm_idx = torch.Tensor(l).sort(0, descending=True)\r\n",
        "    xx_pad = xx_pad[:,perm_idx,:]\r\n",
        "    yy_pad = yy_pad[:,perm_idx]\r\n",
        "\r\n",
        "    return xx_pad, yy_pad, seq_lengths\r\n",
        "\r\n",
        "data_loader = DataLoader(dataset=validation_dataset, batch_size=4, shuffle=True, collate_fn=pad_collate)\r\n",
        "\r\n",
        "#something is wrong here looking at the output\r\n",
        "\r\n",
        "\r\n",
        "#test if it work\r\n",
        "for batch in data_loader:\r\n",
        "    print(batch[0].shape,batch[1].shape,batch[2])\r\n",
        "    print(batch[1])\r\n",
        "    break\r\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3124, 4, 12]) torch.Size([3124, 4]) tensor([3124., 1300., 1065.,  643.])\n",
            "tensor([[26, 26, 32, 15],\n",
            "        [26, 24, 32, 15],\n",
            "        [26,  3,  3, 25],\n",
            "        ...,\n",
            "        [26, 35, 35, 35],\n",
            "        [ 3, 35, 35, 35],\n",
            "        [26, 35, 35, 35]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O1OA1AjGWO-"
      },
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEkFBY5cUsmN"
      },
      "source": [
        "class RNNTagger(nn.Module):\r\n",
        "    \r\n",
        "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\r\n",
        "        super(RNNTagger,self).__init__()    \r\n",
        "        \r\n",
        "        self.n_labels = n_labels\r\n",
        "        self.hidden_dim = hidden_dim\r\n",
        "\r\n",
        "        # RNN layer. We're using a bidirectional GRU\r\n",
        "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \r\n",
        "                          bidirectional=True, num_layers=n_layers)\r\n",
        "        \r\n",
        "        # Output layer. The input will be two times\r\n",
        "        # the RNN size since we are using a bidirectional RNN.\r\n",
        "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\r\n",
        "    \r\n",
        "        # Loss function that we will use during training.\r\n",
        "        self.loss = torch.nn.CrossEntropyLoss(reduction='sum',ignore_index = tag_to_ix[PAD])\r\n",
        "        \r\n",
        "    def compute_outputs(self, sentences,sentences_len):\r\n",
        "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\r\n",
        "        rnn_out, _ = self.rnn(sentences)\r\n",
        "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\r\n",
        "\r\n",
        "        out = self.top_layer(rnn_out)\r\n",
        "       \r\n",
        "        # # Find the positions where the token is a dummy padding token.\r\n",
        "        # pad_mask = (sentences == self.pad_word_id).float()\r\n",
        "\r\n",
        "        # # For these positions, we add some large number in the column corresponding\r\n",
        "        # # to the dummy padding label.\r\n",
        "        # out[:, :, self.pad_label_id] += pad_mask*10000\r\n",
        "\r\n",
        "        return out\r\n",
        "                \r\n",
        "    def forward(self, sentences, labels, sentences_len):\r\n",
        "        # First computes the predictions, and then the loss function.\r\n",
        "        \r\n",
        "        # Compute the outputs. The shape is (max_len, n_sentences, n_labels).\r\n",
        "        scores = self.compute_outputs(sentences,sentences_len)\r\n",
        "        \r\n",
        "        # Flatten the outputs and the gold-standard labels, to compute the loss.\r\n",
        "        # The input to this loss needs to be one 2-dimensional and one 1-dimensional tensor.\r\n",
        "        scores = scores.view(-1, self.n_labels)\r\n",
        "        labels = labels.view(-1)\r\n",
        "        return self.loss(scores, labels)\r\n",
        "\r\n",
        "    def predict(self, sentences,sentences_len):\r\n",
        "        # Compute the outputs from the linear units.\r\n",
        "        scores = self.compute_outputs(sentences,sentences_len)\r\n",
        "\r\n",
        "        # Select the top-scoring labels. The shape is now (max_len, n_sentences).\r\n",
        "        predicted = scores.argmax(dim=2)\r\n",
        "\r\n",
        "        # We transpose the prediction to (n_sentences, max_len), and convert it\r\n",
        "        # to a NumPy matrix.\r\n",
        "        return predicted.t().cpu().numpy()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE7itQ88Qx17"
      },
      "source": [
        "class RNNCRFTagger(nn.Module):\r\n",
        "    def __init__(self, input_dim, hidden_dim, n_labels,n_layers =1):\r\n",
        "        super(RNNCRFTagger,self).__init__()    \r\n",
        "        \r\n",
        "        self.n_labels = n_labels\r\n",
        "        self.hidden_dim = hidden_dim\r\n",
        "\r\n",
        "        self.rnn = nn.GRU(input_size=input_dim, hidden_size=hidden_dim //2, \r\n",
        "                          bidirectional=True, num_layers=n_layers)\r\n",
        "\r\n",
        "        self.top_layer = nn.Linear(hidden_dim, self.n_labels)\r\n",
        "    \r\n",
        "        self.crf = CRF(self.n_labels)\r\n",
        "        \r\n",
        "    def compute_outputs(self, sentences,sentences_len):\r\n",
        "        ## should I initialize here??\r\n",
        "        sentences = torch.nn.utils.rnn.pack_padded_sequence(sentences, sentences_len)\r\n",
        "        rnn_out, _ = self.rnn(sentences)\r\n",
        "        rnn_out,_ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out)\r\n",
        "\r\n",
        "        out = self.top_layer(rnn_out)\r\n",
        "      \r\n",
        "        return out\r\n",
        "                \r\n",
        "    def forward(self, sentences, labels, sentences_len):\r\n",
        "        # Compute the outputs of the lower layers, which will be used as emission\r\n",
        "        # scores for the CRF.\r\n",
        "        scores = self.compute_outputs(sentences,sentences_len)\r\n",
        "\r\n",
        "        # We return the loss value. The CRF returns the log likelihood, but we return \r\n",
        "        # the *negative* log likelihood as the loss value.            \r\n",
        "        # PyTorch's optimizers *minimize* the loss, while we want to *maximize* the\r\n",
        "        # log likelihood.\r\n",
        "\r\n",
        "        pad_mask = torch.arange(max(sentences_len))[:, None] < sentences_len[None, :]\r\n",
        "        pad_mask = pad_mask.byte().to(device)\r\n",
        "        return -self.crf(scores, labels, mask = pad_mask )\r\n",
        "            \r\n",
        "    def predict(self, sentences,sentences_len):\r\n",
        "        # Compute the emission scores, as above.\r\n",
        "        scores = self.compute_outputs(sentences,sentences_len)\r\n",
        "\r\n",
        "        # Apply the Viterbi algorithm to get the predictions. This implementation returns\r\n",
        "        # the result as a list of lists (not a tensor), corresponding to a matrix\r\n",
        "        # of shape (n_sentences, max_len).\r\n",
        "        pad_mask = torch.arange(max(sentences_len))[:, None] < sentences_len[None, :]\r\n",
        "        pad_mask = pad_mask.byte().to(device)\r\n",
        "        return self.crf.decode(scores,mask = pad_mask)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXixmVQfvw8T"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m_nj4HCuCe1"
      },
      "source": [
        "# TODO: search over the best hyperparameters"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAMSIlw0AJb6"
      },
      "source": [
        "def training_loop(model, optimizer, train_dataloader, val_dataloader, n_epochs):\r\n",
        "    history = defaultdict(list)  \r\n",
        "    for i_epoch in range(1,n_epochs +1):\r\n",
        "        t0 = time.time()\r\n",
        "        loss_sum = 0\r\n",
        "        accuracy_sum = 0\r\n",
        "        model.train()\r\n",
        "        for seqs, targets, lens in train_dataloader: #seqs, targets, lens are batches\r\n",
        "            seqs, targets = seqs.to(device), targets.to(device)\r\n",
        "            optimizer.zero_grad()\r\n",
        "\r\n",
        "            loss = model(seqs,targets,lens) / sum(lens) #normalize for the number of symbol considered (without padding)\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "            loss_sum += loss.item()\r\n",
        "\r\n",
        "            predicted = model.predict(seqs,lens)\r\n",
        "            for i,p in enumerate(predicted):\r\n",
        "                acc= accuracy_score(p,targets[:,i][:len(p)].cpu()) #compute the accuracy without considering the padding\r\n",
        "                accuracy_sum += acc/len(lens) #normalize according to the number of sequences in the batch\r\n",
        "\r\n",
        "        train_loss = loss_sum/len(train_dataloader)\r\n",
        "        train_accuracy = accuracy_sum/len(train_dataloader) #normalize according to the number of batches\r\n",
        "        history[\"train_loss\"].append(train_loss)\r\n",
        "        history[\"train_accuracy\"].append(train_accuracy)\r\n",
        "\r\n",
        "\r\n",
        "        # Evaluate on the validation set.\r\n",
        "        model.eval()\r\n",
        "        all_predicted = []\r\n",
        "        all_targets = []\r\n",
        "        with torch.no_grad():\r\n",
        "            for seqs,targets, lens in val_dataloader:\r\n",
        "                # Predict the model's output on a batch.\r\n",
        "                predicted = model.predict(seqs.to(device),lens)                   \r\n",
        "                # Update the evaluation statistics.\r\n",
        "                for i,p in enumerate(predicted):\r\n",
        "                    all_predicted.append(torch.Tensor(p))\r\n",
        "                    all_targets.append(targets[0:int(lens[i]),i])\r\n",
        "                \r\n",
        "        # Compute the overall accuracy for the validation set\r\n",
        "        val_accuracy = accuracy_score(torch.cat(all_predicted),torch.cat(all_targets))\r\n",
        "        history[\"val_accuracy\"].append(val_accuracy)\r\n",
        "\r\n",
        "    \r\n",
        "        t1 = time.time()\r\n",
        "        print(f'Epoch {i_epoch}: train loss = {train_loss:.4f}, train_accuracy: {train_accuracy:.4f},val_accuracy: {val_accuracy:.4f}, time = {t1-t0:.4f}')\r\n",
        "    return history"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "2g2st8znpGW_",
        "outputId": "174e458c-7b3f-4cfb-ac81-b355f640db39"
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\r\n",
        "print(f\"Training device: {device}\")\r\n",
        "\r\n",
        "n_epochs = 50\r\n",
        "HIDDEN_DIM = 72\r\n",
        "LEARNING_WEIGHT = 0.05\r\n",
        "WEIGHT_DECAY = 1e-4\r\n",
        "BATCH_SIZE = 16\r\n",
        "\r\n",
        "train_dataset = PSDataset(dict_dataset,path_train, transform_chrom,transform_diat,True, truncate = 600)\r\n",
        "validation_dataset = PSDataset(dict_dataset,path_validation, transform_chrom,transform_diat, False)\r\n",
        "\r\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,collate_fn=pad_collate)\r\n",
        "val_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True,collate_fn=pad_collate)\r\n",
        "\r\n",
        "# model = RNNCRFTagger(12,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\r\n",
        "model = RNNTagger(12,HIDDEN_DIM,len(tag_to_ix), n_layers =1)\r\n",
        "model = model.to(device)\r\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_WEIGHT, weight_decay=WEIGHT_DECAY)\r\n",
        "# otimizer = torch.optim.Adam(model.parameters(),lr = 0.05, weight_decay=1e-4)\r\n",
        "\r\n",
        "history = training_loop(model,optimizer,train_dataloader,val_dataloader, n_epochs)\r\n",
        "\r\n",
        "# After the final evaluation, we print more detailed evaluation statistics,\r\n",
        "plt.plot(history['train_loss'])\r\n",
        "plt.plot(history['train_accuracy'])\r\n",
        "plt.plot(history['val_accuracy'])\r\n",
        "plt.legend(['training loss', 'training accuracy', 'validation_accuracy'])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training device: cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-5a4f5b364e9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# otimizer = torch.optim.Adam(model.parameters(),lr = 0.05, weight_decay=1e-4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# After the final evaluation, we print more detailed evaluation statistics,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-d694f3517f3f>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(model, optimizer, train_dataloader, val_dataloader, n_epochs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Compute the overall accuracy for the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [106708, 50080]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "tTv2BrGbvSHh",
        "outputId": "801ff32d-24dc-4434-a436-17d9ca832214"
      },
      "source": [
        "torch.save(model, \"model_asap_crf300.pkl\")\r\n",
        "files.download(\"model_asap_crf300.pkl\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2becd0ee-42f6-49a2-a019-3deadfab3a8b\", \"model_asap_crf300.pkl\", 63501)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXcmLpCKt28l"
      },
      "source": [
        "## Test on Mdata dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BacUqgD5usGL"
      },
      "source": [
        "# load the dataset\r\n",
        "with open('/content/pitch-spelling/datasets/musedata.pkl', 'rb') as fid:\r\n",
        "     full_mdata_dict_dataset = pickle.load( fid)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgaUwW2fuwg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89fc5f7d-884a-4ee6-fc34-b3d512f0c4c7"
      },
      "source": [
        "mdata_paths = list(set([e[\"original_path\"] for e in full_mdata_dict_dataset ]))\r\n",
        "\r\n",
        "# # remove the symbphony No.100 from Haydn because of the enharmonic transposition\r\n",
        "# paths.remove(\"datasets\\\\opnd\\\\haydndoversyms-10004m.opnd-m\")\r\n",
        "\r\n",
        "# print(paths)\r\n",
        "print(len(mdata_paths), \"different pieces\")\r\n",
        "print(\"Average number of notes: \", np.mean([len(e[\"midi_number\"]) for e in full_mdata_dict_dataset ]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "216 different pieces\n",
            "Average number of notes:  858.6319771007974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-Fg6gJKvNLt"
      },
      "source": [
        "mdata_dataset = PSDataset(full_mdata_dict_dataset,mdata_paths, transform_chrom,transform_diat,False)\r\n",
        "mdata_dataloader  = DataLoader(mdata_dataset,  batch_size=64, shuffle=False, collate_fn=pad_collate)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml905Mtdvj-T"
      },
      "source": [
        "all_inputs = []\r\n",
        "all_outputs = []\r\n",
        "all_targets = []\r\n",
        "model.eval() # Evaluation mode (e.g. disable dropout)\r\n",
        "with torch.no_grad(): # Disable gradient tracking\r\n",
        "  for seqs, targets,lens in mdata_dataloader:\r\n",
        "    # Move data to device\r\n",
        "    seqs = seqs.to(device)\r\n",
        "\r\n",
        "    # Predict the model's output on a batch.\r\n",
        "    predicted = model.predict(seqs,lens)                   \r\n",
        "    # Update the evaluation statistics.\r\n",
        "    for i,p in enumerate(predicted):\r\n",
        "        all_inputs.append(torch.argmax(seqs[0:int(lens[i]),i,:].cpu(),1).numpy())\r\n",
        "        all_outputs.append(torch.Tensor(p))\r\n",
        "        all_targets.append(targets[0:int(lens[i]),i])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsefdSHxvrWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33785b90-5e03-4a6d-86dd-92b6b763a505"
      },
      "source": [
        "# Divide accuracy according to author\r\n",
        "authors = []\r\n",
        "\r\n",
        "for sequence in all_inputs:\r\n",
        "    author = [e[\"original_path\"].split(\"\\\\\")[-1][:3] for e in full_mdata_dict_dataset\r\n",
        "              if len(e[\"midi_number\"]) == len(sequence) and\r\n",
        "              list(e[\"midi_number\"]) ==list(sequence) ]\r\n",
        "    # assert len(author) == 1\r\n",
        "    authors.append(author[0])\r\n",
        "\r\n",
        "considered_authors = list(set(authors))\r\n",
        "print(considered_authors)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bac', 'hay', 'viv', 'cor', 'han', 'moz', 'tel', 'bee']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgNt_yG7vrfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8473393f-dac6-4930-9d9e-da9c1046f1ab"
      },
      "source": [
        "errors_per_author = {}\r\n",
        "accuracy_per_author = {}\r\n",
        "for ca in considered_authors:\r\n",
        "    # ca_inputs = torch.cat([all_inputs[i] for i,a in enumerate(authors) if a == ca])\r\n",
        "    ca_outputs = torch.cat([all_outputs[i] for i,a in enumerate(authors) if a == ca])\r\n",
        "    ca_targets = torch.cat([all_targets[i] for i,a in enumerate(authors) if a == ca])\r\n",
        "    # print(ca_inputs.shape,ca_outputs.shape,ca_targets.shape,ca_predicted_pitches.shape)\r\n",
        "    ca_acc = accuracy_score(ca_outputs,ca_targets)\r\n",
        "    accuracy_per_author[ca] = float(ca_acc)\r\n",
        "    errors_per_author[ca] = int(len(ca_targets) - sum(torch.eq(ca_outputs,ca_targets)))\r\n",
        "\r\n",
        "print(errors_per_author)\r\n",
        "print(accuracy_per_author)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'bac': 124, 'hay': 371, 'viv': 110, 'cor': 22, 'han': 67, 'moz': 184, 'tel': 64, 'bee': 270}\n",
            "{'bac': 0.9949398082024077, 'hay': 0.9848509595753369, 'viv': 0.9955096542433768, 'cor': 0.999101784183236, 'han': 0.997265306122449, 'moz': 0.9924879562341798, 'tel': 0.9973877551020408, 'bee': 0.9889764422488058}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5s0d56evrje"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVvP1eH8vrl3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}